{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPool2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "# from resnets_utils import *\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    \n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    \"\"\"    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "\n",
    "    ##### SHORTCUT PATH #### (≈2 lines)\n",
    "    X_shortcut = Conv2D(filters = F3, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1',\n",
    "                        kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape=(64, 64, 3), classes=5):\n",
    "    \"\"\"\n",
    "    ResNet50:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPool2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Stage 3 (≈4 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    # Stage 4 (≈6 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    # Stage 5 (≈3 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "       \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape = (64, 64, 3), classes = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv').drop(columns=['Id'])\n",
    "X = np.array(df.iloc[:, 1:])\n",
    "y = to_categorical(np.array(df.iloc[:, 0]))\n",
    "\n",
    "# Convert the training and test images into 3 channels\n",
    "X = np.dstack([X] * 3)\n",
    "# Reshape images as per the tensor format required by tensorflow\n",
    "X = X.reshape(-1, 28, 28, 3)\n",
    "X = np.asarray([img_to_array(array_to_img(im, scale=False).resize((64,64))) for im in X])\n",
    "X = X.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 64, 64, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 6000 samples\n",
      "Epoch 1/25\n",
      "48000/48000 [==============================] - 46s 952us/sample - loss: 0.6341 - accuracy: 0.7706 - val_loss: 49.8181 - val_accuracy: 0.6758\n",
      "Epoch 2/25\n",
      "48000/48000 [==============================] - 34s 718us/sample - loss: 0.4306 - accuracy: 0.8296 - val_loss: 0.3576 - val_accuracy: 0.8590\n",
      "Epoch 3/25\n",
      "48000/48000 [==============================] - 35s 723us/sample - loss: 0.3535 - accuracy: 0.8574 - val_loss: 0.5823 - val_accuracy: 0.7727\n",
      "Epoch 4/25\n",
      "48000/48000 [==============================] - 35s 726us/sample - loss: 0.3280 - accuracy: 0.8677 - val_loss: 0.3106 - val_accuracy: 0.8778\n",
      "Epoch 5/25\n",
      "48000/48000 [==============================] - 35s 727us/sample - loss: 0.2984 - accuracy: 0.8780 - val_loss: 0.3533 - val_accuracy: 0.8610\n",
      "Epoch 6/25\n",
      "48000/48000 [==============================] - 35s 723us/sample - loss: 0.2818 - accuracy: 0.8856 - val_loss: 0.4454 - val_accuracy: 0.8302\n",
      "Epoch 7/25\n",
      "48000/48000 [==============================] - 35s 727us/sample - loss: 0.4245 - accuracy: 0.8390 - val_loss: 24.8276 - val_accuracy: 0.5235\n",
      "Epoch 8/25\n",
      "48000/48000 [==============================] - 35s 726us/sample - loss: 0.3818 - accuracy: 0.8502 - val_loss: 0.3407 - val_accuracy: 0.8615\n",
      "Epoch 9/25\n",
      "48000/48000 [==============================] - 35s 724us/sample - loss: 0.3146 - accuracy: 0.8694 - val_loss: 0.3732 - val_accuracy: 0.8488\n",
      "Epoch 10/25\n",
      "48000/48000 [==============================] - 35s 731us/sample - loss: 0.3970 - accuracy: 0.8416 - val_loss: 0.4415 - val_accuracy: 0.8170\n",
      "Epoch 11/25\n",
      "48000/48000 [==============================] - 35s 723us/sample - loss: 0.3639 - accuracy: 0.8536 - val_loss: 187.8167 - val_accuracy: 0.7045\n",
      "Epoch 12/25\n",
      "48000/48000 [==============================] - 35s 721us/sample - loss: 0.3275 - accuracy: 0.8683 - val_loss: 0.3020 - val_accuracy: 0.8848\n",
      "Epoch 13/25\n",
      "48000/48000 [==============================] - 35s 725us/sample - loss: 0.2912 - accuracy: 0.8822 - val_loss: 0.4849 - val_accuracy: 0.8120\n",
      "Epoch 14/25\n",
      "48000/48000 [==============================] - 35s 720us/sample - loss: 0.2644 - accuracy: 0.8916 - val_loss: 0.4206 - val_accuracy: 0.8378\n",
      "Epoch 15/25\n",
      "48000/48000 [==============================] - 35s 726us/sample - loss: 0.2445 - accuracy: 0.9004 - val_loss: 0.3101 - val_accuracy: 0.8748\n",
      "Epoch 16/25\n",
      "48000/48000 [==============================] - 35s 722us/sample - loss: 0.2504 - accuracy: 0.8976 - val_loss: 0.3193 - val_accuracy: 0.8690\n",
      "Epoch 17/25\n",
      "48000/48000 [==============================] - 35s 724us/sample - loss: 0.2276 - accuracy: 0.9065 - val_loss: 0.3054 - val_accuracy: 0.8775\n",
      "Epoch 18/25\n",
      "48000/48000 [==============================] - 35s 720us/sample - loss: 0.2987 - accuracy: 0.8877 - val_loss: 0.3123 - val_accuracy: 0.8743\n",
      "Epoch 19/25\n",
      "48000/48000 [==============================] - 35s 726us/sample - loss: 0.2214 - accuracy: 0.9100 - val_loss: 0.3331 - val_accuracy: 0.8680\n",
      "Epoch 20/25\n",
      "48000/48000 [==============================] - 35s 723us/sample - loss: 0.2022 - accuracy: 0.9156 - val_loss: 0.3084 - val_accuracy: 0.8802\n",
      "Epoch 21/25\n",
      "48000/48000 [==============================] - 35s 721us/sample - loss: 0.1870 - accuracy: 0.9229 - val_loss: 0.3411 - val_accuracy: 0.8742\n",
      "Epoch 22/25\n",
      "48000/48000 [==============================] - 35s 725us/sample - loss: 0.1838 - accuracy: 0.9252 - val_loss: 0.4264 - val_accuracy: 0.8395\n",
      "Epoch 23/25\n",
      "48000/48000 [==============================] - 35s 722us/sample - loss: 0.1693 - accuracy: 0.9320 - val_loss: 0.4705 - val_accuracy: 0.8427\n",
      "Epoch 24/25\n",
      "  384/48000 [..............................] - ETA: 33s - loss: 0.1384 - accuracy: 0.9453"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 25, batch_size = 128, verbose = 1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 4s 625us/sample - loss: 0.3802 - accuracy: 0.8853\n",
      "Loss = 0.38016908676425615\n",
      "Test Accuracy = 0.88533336\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(X_test, y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References \n",
    "\n",
    "This notebook presents the ResNet algorithm due to He et al. (2015). The implementation here also took significant inspiration and follows the structure given in the github repository of Francois Chollet: \n",
    "\n",
    "- Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun - [Deep Residual Learning for Image Recognition (2015)](https://arxiv.org/abs/1512.03385)\n",
    "- Francois Chollet's github repository: https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py\n"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "OEpi5",
   "launcher_item_id": "jK9EQ"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
