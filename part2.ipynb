{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv').drop(columns=['Id'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(MinMaxScaler().fit_transform(df.iloc[:,1:]).reshape((-1, 28, 28, 1)), to_categorical(df.iloc[:,0], num_classes=5), test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(28,28,1)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples\n",
      "Epoch 1/40\n",
      "INFO:tensorflow:batch_all_reduce: 24 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 24 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "48000/48000 [==============================] - 42s 878us/sample - loss: 0.8456 - accuracy: 0.6759\n",
      "Epoch 2/40\n",
      "48000/48000 [==============================] - 12s 240us/sample - loss: 0.6095 - accuracy: 0.7552\n",
      "Epoch 3/40\n",
      "48000/48000 [==============================] - 11s 230us/sample - loss: 0.5439 - accuracy: 0.7822\n",
      "Epoch 4/40\n",
      "48000/48000 [==============================] - 10s 215us/sample - loss: 0.4942 - accuracy: 0.8028\n",
      "Epoch 5/40\n",
      "48000/48000 [==============================] - 10s 211us/sample - loss: 0.4595 - accuracy: 0.8204\n",
      "Epoch 6/40\n",
      "48000/48000 [==============================] - 10s 217us/sample - loss: 0.4374 - accuracy: 0.8287\n",
      "Epoch 7/40\n",
      "48000/48000 [==============================] - 10s 213us/sample - loss: 0.4148 - accuracy: 0.8386\n",
      "Epoch 8/40\n",
      "48000/48000 [==============================] - 10s 218us/sample - loss: 0.3968 - accuracy: 0.8452\n",
      "Epoch 9/40\n",
      "48000/48000 [==============================] - 10s 214us/sample - loss: 0.3789 - accuracy: 0.8531\n",
      "Epoch 10/40\n",
      "48000/48000 [==============================] - 10s 215us/sample - loss: 0.3734 - accuracy: 0.8554\n",
      "Epoch 11/40\n",
      "48000/48000 [==============================] - 10s 214us/sample - loss: 0.3587 - accuracy: 0.8609\n",
      "Epoch 12/40\n",
      "48000/48000 [==============================] - 10s 216us/sample - loss: 0.3482 - accuracy: 0.8659\n",
      "Epoch 13/40\n",
      "48000/48000 [==============================] - 10s 213us/sample - loss: 0.3564 - accuracy: 0.8622\n",
      "Epoch 14/40\n",
      "48000/48000 [==============================] - 10s 215us/sample - loss: 0.3400 - accuracy: 0.8692\n",
      "Epoch 15/40\n",
      "48000/48000 [==============================] - 10s 214us/sample - loss: 0.3283 - accuracy: 0.8739\n",
      "Epoch 16/40\n",
      "48000/48000 [==============================] - 10s 214us/sample - loss: 0.3225 - accuracy: 0.8768\n",
      "Epoch 17/40\n",
      "48000/48000 [==============================] - 10s 216us/sample - loss: 0.3089 - accuracy: 0.8823\n",
      "Epoch 18/40\n",
      "48000/48000 [==============================] - 10s 216us/sample - loss: 0.3047 - accuracy: 0.8828\n",
      "Epoch 19/40\n",
      "48000/48000 [==============================] - 10s 212us/sample - loss: 0.2915 - accuracy: 0.8880\n",
      "Epoch 20/40\n",
      "48000/48000 [==============================] - 10s 216us/sample - loss: 0.2914 - accuracy: 0.8865\n",
      "Epoch 21/40\n",
      "48000/48000 [==============================] - 10s 215us/sample - loss: 0.2700 - accuracy: 0.8954\n",
      "Epoch 22/40\n",
      "48000/48000 [==============================] - 10s 213us/sample - loss: 0.2657 - accuracy: 0.8981\n",
      "Epoch 23/40\n",
      "48000/48000 [==============================] - 10s 217us/sample - loss: 0.2621 - accuracy: 0.8990\n",
      "Epoch 24/40\n",
      "48000/48000 [==============================] - 10s 216us/sample - loss: 0.2810 - accuracy: 0.8922\n",
      "Epoch 25/40\n",
      "48000/48000 [==============================] - 10s 214us/sample - loss: 0.2701 - accuracy: 0.8967\n",
      "Epoch 26/40\n",
      "48000/48000 [==============================] - 10s 216us/sample - loss: 0.2556 - accuracy: 0.9016\n",
      "Epoch 27/40\n",
      "48000/48000 [==============================] - 10s 215us/sample - loss: 0.2452 - accuracy: 0.9050\n",
      "Epoch 28/40\n",
      "48000/48000 [==============================] - 10s 215us/sample - loss: 0.2295 - accuracy: 0.9133\n",
      "Epoch 29/40\n",
      "48000/48000 [==============================] - 10s 215us/sample - loss: 0.2344 - accuracy: 0.9106\n",
      "Epoch 30/40\n",
      "48000/48000 [==============================] - 10s 214us/sample - loss: 0.2290 - accuracy: 0.9125\n",
      "Epoch 31/40\n",
      "48000/48000 [==============================] - 10s 214us/sample - loss: 0.2226 - accuracy: 0.9158\n",
      "Epoch 32/40\n",
      "48000/48000 [==============================] - 10s 217us/sample - loss: 0.2160 - accuracy: 0.9181\n",
      "Epoch 33/40\n",
      "48000/48000 [==============================] - 10s 213us/sample - loss: 0.2189 - accuracy: 0.9171\n",
      "Epoch 34/40\n",
      "48000/48000 [==============================] - 10s 215us/sample - loss: 0.2120 - accuracy: 0.9206\n",
      "Epoch 35/40\n",
      "48000/48000 [==============================] - 10s 216us/sample - loss: 0.2082 - accuracy: 0.9202\n",
      "Epoch 36/40\n",
      "48000/48000 [==============================] - 10s 215us/sample - loss: 0.1921 - accuracy: 0.9257\n",
      "Epoch 37/40\n",
      "48000/48000 [==============================] - 10s 214us/sample - loss: 0.1993 - accuracy: 0.9247\n",
      "Epoch 38/40\n",
      "48000/48000 [==============================] - 10s 215us/sample - loss: 0.1969 - accuracy: 0.9256\n",
      "Epoch 39/40\n",
      "48000/48000 [==============================] - 10s 216us/sample - loss: 0.1978 - accuracy: 0.9257\n",
      "Epoch 40/40\n",
      "48000/48000 [==============================] - 10s 213us/sample - loss: 0.2023 - accuracy: 0.9229\n",
      "12000/12000 [==============================] - 5s 394us/sample - loss: 0.2691 - accuracy: 0.8970\n",
      "Accuracy: 0.897\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=40, batch_size=128)\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 375 steps, validate on 12000 samples\n",
      "Epoch 1/40\n",
      "375/375 [==============================] - 23s 63ms/step - loss: 0.6649 - accuracy: 0.7512 - val_loss: 0.3261 - val_accuracy: 0.8732\n",
      "Epoch 2/40\n",
      "375/375 [==============================] - 21s 55ms/step - loss: 0.5207 - accuracy: 0.7897 - val_loss: 0.3525 - val_accuracy: 0.8547\n",
      "Epoch 3/40\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 0.4928 - accuracy: 0.8031 - val_loss: 0.3338 - val_accuracy: 0.8637\n",
      "Epoch 4/40\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.4783 - accuracy: 0.8084 - val_loss: 0.4013 - val_accuracy: 0.8298\n",
      "Epoch 5/40\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 0.4631 - accuracy: 0.8143 - val_loss: 0.6324 - val_accuracy: 0.7389\n",
      "Epoch 6/40\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 0.4547 - accuracy: 0.8170 - val_loss: 0.3197 - val_accuracy: 0.8668\n",
      "Epoch 7/40\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.4453 - accuracy: 0.8206 - val_loss: 0.3496 - val_accuracy: 0.8581\n",
      "Epoch 8/40\n",
      "375/375 [==============================] - 20s 53ms/step - loss: 0.4388 - accuracy: 0.8221 - val_loss: 0.3143 - val_accuracy: 0.8717\n",
      "Epoch 9/40\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.4376 - accuracy: 0.8231 - val_loss: 0.4014 - val_accuracy: 0.8280\n",
      "Epoch 10/40\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 0.4267 - accuracy: 0.8282 - val_loss: 0.4004 - val_accuracy: 0.8307\n",
      "Epoch 11/40\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.4213 - accuracy: 0.8292 - val_loss: 0.4670 - val_accuracy: 0.7976\n",
      "Epoch 12/40\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 0.4198 - accuracy: 0.8310 - val_loss: 0.7995 - val_accuracy: 0.7047\n",
      "Epoch 13/40\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.4199 - accuracy: 0.8310 - val_loss: 0.6813 - val_accuracy: 0.7310\n",
      "Epoch 14/40\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.4118 - accuracy: 0.8340 - val_loss: 0.7324 - val_accuracy: 0.7094\n",
      "Epoch 15/40\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 0.4080 - accuracy: 0.8346 - val_loss: 0.4586 - val_accuracy: 0.8042\n",
      "Epoch 16/40\n",
      "375/375 [==============================] - 21s 55ms/step - loss: 0.4039 - accuracy: 0.8365 - val_loss: 0.4118 - val_accuracy: 0.8252\n",
      "Epoch 17/40\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.3989 - accuracy: 0.8367 - val_loss: 0.4268 - val_accuracy: 0.8157\n",
      "Epoch 18/40\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 0.3984 - accuracy: 0.8392 - val_loss: 0.4781 - val_accuracy: 0.7966\n",
      "Epoch 19/40\n",
      "375/375 [==============================] - 26s 69ms/step - loss: 0.3938 - accuracy: 0.8388 - val_loss: 0.4225 - val_accuracy: 0.8142\n",
      "Epoch 20/40\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 0.3950 - accuracy: 0.8389 - val_loss: 0.3886 - val_accuracy: 0.8293\n",
      "Epoch 21/40\n",
      "375/375 [==============================] - 24s 63ms/step - loss: 0.3894 - accuracy: 0.8430 - val_loss: 0.4141 - val_accuracy: 0.8250\n",
      "Epoch 22/40\n",
      "375/375 [==============================] - 20s 53ms/step - loss: 0.3907 - accuracy: 0.8420 - val_loss: 0.4415 - val_accuracy: 0.8083\n",
      "Epoch 23/40\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.3859 - accuracy: 0.8432 - val_loss: 0.6980 - val_accuracy: 0.7316\n",
      "Epoch 24/40\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.3797 - accuracy: 0.8465 - val_loss: 0.7241 - val_accuracy: 0.7229\n",
      "Epoch 25/40\n",
      "375/375 [==============================] - 21s 55ms/step - loss: 0.3816 - accuracy: 0.8464 - val_loss: 0.3788 - val_accuracy: 0.8385\n",
      "Epoch 26/40\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.3748 - accuracy: 0.8471 - val_loss: 0.4309 - val_accuracy: 0.8132\n",
      "Epoch 27/40\n",
      "375/375 [==============================] - 21s 55ms/step - loss: 0.3758 - accuracy: 0.8456 - val_loss: 0.8617 - val_accuracy: 0.6983\n",
      "Epoch 28/40\n",
      "375/375 [==============================] - 26s 70ms/step - loss: 0.3778 - accuracy: 0.8471 - val_loss: 0.4724 - val_accuracy: 0.7988\n",
      "Epoch 29/40\n",
      "375/375 [==============================] - 25s 67ms/step - loss: 0.3715 - accuracy: 0.8473 - val_loss: 0.4421 - val_accuracy: 0.8111\n",
      "Epoch 30/40\n",
      "375/375 [==============================] - 26s 68ms/step - loss: 0.3750 - accuracy: 0.8461 - val_loss: 0.4279 - val_accuracy: 0.8167\n",
      "Epoch 31/40\n",
      "375/375 [==============================] - 27s 71ms/step - loss: 0.3682 - accuracy: 0.8516 - val_loss: 0.4974 - val_accuracy: 0.7922\n",
      "Epoch 32/40\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 0.3680 - accuracy: 0.8523 - val_loss: 0.5237 - val_accuracy: 0.7815\n",
      "Epoch 33/40\n",
      "375/375 [==============================] - 25s 66ms/step - loss: 0.3641 - accuracy: 0.8543 - val_loss: 0.5711 - val_accuracy: 0.7768\n",
      "Epoch 34/40\n",
      "375/375 [==============================] - 25s 68ms/step - loss: 0.3607 - accuracy: 0.8537 - val_loss: 0.5481 - val_accuracy: 0.7767\n",
      "Epoch 35/40\n",
      "375/375 [==============================] - 26s 69ms/step - loss: 0.3610 - accuracy: 0.8537 - val_loss: 0.4310 - val_accuracy: 0.8139\n",
      "Epoch 36/40\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.3644 - accuracy: 0.8502 - val_loss: 0.3289 - val_accuracy: 0.8587\n",
      "Epoch 37/40\n",
      "375/375 [==============================] - 20s 53ms/step - loss: 0.3589 - accuracy: 0.8547 - val_loss: 0.6416 - val_accuracy: 0.7483\n",
      "Epoch 38/40\n",
      "375/375 [==============================] - 26s 70ms/step - loss: 0.3548 - accuracy: 0.8556 - val_loss: 0.5931 - val_accuracy: 0.7673\n",
      "Epoch 39/40\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.3516 - accuracy: 0.8568 - val_loss: 0.3865 - val_accuracy: 0.8396\n",
      "Epoch 40/40\n",
      "375/375 [==============================] - 19s 50ms/step - loss: 0.3534 - accuracy: 0.8562 - val_loss: 0.4077 - val_accuracy: 0.8264\n",
      "12000/12000 [==============================] - 1s 118us/sample - loss: 0.4077 - accuracy: 0.8264\n",
      "Loss: 0.4077\n",
      "Accuracy: 0.8264\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rotation_range = 8, zoom_range = 0.1, shear_range = 0.3, width_shift_range=0.08, height_shift_range=0.08, vertical_flip=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size = 128), epochs = 40, validation_data = (X_test, y_test), steps_per_epoch=X_train.shape[0] // 128, callbacks = [reduce_lr])\n",
    "score = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Loss: {:.4f}'.format(score[0]))\n",
    "print('Accuracy: {:.4f}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(28,28,1)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "    Dropout(0.5),\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Conv2D(filters=256, kernel_size=(3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 8s 174us/sample - loss: 0.3455 - accuracy: 0.8625 - val_loss: 0.2962 - val_accuracy: 0.8742\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 8s 165us/sample - loss: 0.3384 - accuracy: 0.8649 - val_loss: 0.4136 - val_accuracy: 0.8307\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.3269 - accuracy: 0.8704 - val_loss: 0.2907 - val_accuracy: 0.8819\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 8s 165us/sample - loss: 0.3165 - accuracy: 0.8746 - val_loss: 0.2683 - val_accuracy: 0.8883\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 8s 162us/sample - loss: 0.3184 - accuracy: 0.8736 - val_loss: 0.2603 - val_accuracy: 0.8951\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 8s 166us/sample - loss: 0.3105 - accuracy: 0.8750 - val_loss: 0.4409 - val_accuracy: 0.8234\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.2999 - accuracy: 0.8806 - val_loss: 0.3219 - val_accuracy: 0.8682\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.2952 - accuracy: 0.8818 - val_loss: 0.3765 - val_accuracy: 0.8480\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.2888 - accuracy: 0.8851 - val_loss: 0.2827 - val_accuracy: 0.8829\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.2845 - accuracy: 0.8875 - val_loss: 0.4459 - val_accuracy: 0.8241\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 8s 165us/sample - loss: 0.2825 - accuracy: 0.8875 - val_loss: 0.2717 - val_accuracy: 0.8895\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 8s 167us/sample - loss: 0.2733 - accuracy: 0.8911 - val_loss: 0.2935 - val_accuracy: 0.8824\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.2659 - accuracy: 0.8935 - val_loss: 0.2624 - val_accuracy: 0.8955\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.2634 - accuracy: 0.8953 - val_loss: 0.3654 - val_accuracy: 0.8553\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 8s 167us/sample - loss: 0.2556 - accuracy: 0.8986 - val_loss: 0.2570 - val_accuracy: 0.8951\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 8s 165us/sample - loss: 0.2485 - accuracy: 0.9015 - val_loss: 0.2452 - val_accuracy: 0.9027\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 8s 166us/sample - loss: 0.2436 - accuracy: 0.9034 - val_loss: 0.3099 - val_accuracy: 0.8779\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 8s 165us/sample - loss: 0.2420 - accuracy: 0.9054 - val_loss: 0.2895 - val_accuracy: 0.8855\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.2434 - accuracy: 0.9034 - val_loss: 0.2684 - val_accuracy: 0.8938\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.2284 - accuracy: 0.9102 - val_loss: 0.2619 - val_accuracy: 0.8974\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 8s 162us/sample - loss: 0.2241 - accuracy: 0.9109 - val_loss: 0.2859 - val_accuracy: 0.8867\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 8s 165us/sample - loss: 0.2216 - accuracy: 0.9138 - val_loss: 0.2518 - val_accuracy: 0.9011\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.2180 - accuracy: 0.9153 - val_loss: 0.3787 - val_accuracy: 0.8551\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 8s 162us/sample - loss: 0.2130 - accuracy: 0.9147 - val_loss: 0.4058 - val_accuracy: 0.8493\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 8s 165us/sample - loss: 0.2069 - accuracy: 0.9176 - val_loss: 0.2882 - val_accuracy: 0.8891\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 8s 166us/sample - loss: 0.2030 - accuracy: 0.9203 - val_loss: 0.2504 - val_accuracy: 0.9026\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 8s 165us/sample - loss: 0.1983 - accuracy: 0.9217 - val_loss: 0.2862 - val_accuracy: 0.8923\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 8s 165us/sample - loss: 0.1897 - accuracy: 0.9263 - val_loss: 0.2842 - val_accuracy: 0.8910\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 8s 167us/sample - loss: 0.2016 - accuracy: 0.9215 - val_loss: 0.2585 - val_accuracy: 0.8984\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 8s 166us/sample - loss: 0.1885 - accuracy: 0.9272 - val_loss: 0.2518 - val_accuracy: 0.9033\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.1858 - accuracy: 0.9274 - val_loss: 0.2815 - val_accuracy: 0.8967\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.1784 - accuracy: 0.9313 - val_loss: 0.3002 - val_accuracy: 0.8891\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.1672 - accuracy: 0.9348 - val_loss: 0.2957 - val_accuracy: 0.8940\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.1787 - accuracy: 0.9306 - val_loss: 0.3181 - val_accuracy: 0.8822\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.1720 - accuracy: 0.9330 - val_loss: 0.3110 - val_accuracy: 0.8817\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.1661 - accuracy: 0.9346 - val_loss: 0.2875 - val_accuracy: 0.8928\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 8s 165us/sample - loss: 0.1613 - accuracy: 0.9374 - val_loss: 0.4459 - val_accuracy: 0.8545\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.1573 - accuracy: 0.9396 - val_loss: 0.2757 - val_accuracy: 0.8976\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 8s 162us/sample - loss: 0.1545 - accuracy: 0.9406 - val_loss: 0.2943 - val_accuracy: 0.8967\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 8s 169us/sample - loss: 0.1542 - accuracy: 0.9400 - val_loss: 0.4682 - val_accuracy: 0.8486\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.1505 - accuracy: 0.9415 - val_loss: 0.3745 - val_accuracy: 0.8727\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.1537 - accuracy: 0.9422 - val_loss: 0.2869 - val_accuracy: 0.8975\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.1416 - accuracy: 0.9458 - val_loss: 0.2733 - val_accuracy: 0.9047\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.1442 - accuracy: 0.9455 - val_loss: 0.3273 - val_accuracy: 0.8905\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 8s 168us/sample - loss: 0.1412 - accuracy: 0.9455 - val_loss: 0.3243 - val_accuracy: 0.8876\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.1370 - accuracy: 0.9481 - val_loss: 0.3886 - val_accuracy: 0.8723\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.1382 - accuracy: 0.9474 - val_loss: 0.2941 - val_accuracy: 0.8956\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.1385 - accuracy: 0.9480 - val_loss: 0.2713 - val_accuracy: 0.9033\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.1281 - accuracy: 0.9520 - val_loss: 0.2917 - val_accuracy: 0.9000\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 8s 162us/sample - loss: 0.1339 - accuracy: 0.9488 - val_loss: 0.2718 - val_accuracy: 0.9070\n",
      "12000/12000 [==============================] - 2s 145us/sample - loss: 0.2718 - accuracy: 0.9070\n",
      "Accuracy: 0.907\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=128, validation_data = (X_test, y_test), callbacks = [reduce_lr])\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
