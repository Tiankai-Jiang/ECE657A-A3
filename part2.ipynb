{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_plot(history, name):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(history['accuracy'], label='training accuracy')\n",
    "    plt.plot(history['loss'], label='training loss')    \n",
    "    plt.plot(history['val_accuracy'], label='validation accuracy')\n",
    "    plt.plot(history['val_loss'], label='validation loss')\n",
    "    plt.title(name + ' Accuracy and Loss')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend()\n",
    "#     plt.savefig(name +'_Result.png', bbox_inches='tight', dpi=300)\n",
    "    return plt.show()\n",
    "\n",
    "def gen_csv(model, name):\n",
    "    result = dfTest[['Id']].copy()\n",
    "    result['Label'] = model.predict_classes(MinMaxScaler().fit_transform(dfTest.iloc[:,1:]).reshape((-1, 28, 28, 1)))\n",
    "    result.to_csv('result' + name + '.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv').drop(columns=['Id'])\n",
    "dfTest = pd.read_csv('testX.csv')\n",
    "X_train, X_val, y_train, y_val = train_test_split(MinMaxScaler().fit_transform(df.iloc[:,1:]).reshape((-1, 28, 28, 1)), to_categorical(df.iloc[:,0], num_classes=5), test_size=0.2, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(MinMaxScaler().fit_transform(df.iloc[:,1:]).reshape((-1, 28, 28, 1)), to_categorical(df.iloc[:,0], num_classes=5), test_size=0.2, random_state=42)\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.67, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/30\n",
      "48000/48000 [==============================] - 8s 166us/sample - loss: 0.5811 - accuracy: 0.7552 - val_loss: 0.4182 - val_accuracy: 0.8266\n",
      "Epoch 2/30\n",
      "48000/48000 [==============================] - 7s 152us/sample - loss: 0.4314 - accuracy: 0.8243 - val_loss: 0.3643 - val_accuracy: 0.8585\n",
      "Epoch 3/30\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.3832 - accuracy: 0.8433 - val_loss: 0.3693 - val_accuracy: 0.8502\n",
      "Epoch 4/30\n",
      "48000/48000 [==============================] - 7s 156us/sample - loss: 0.3530 - accuracy: 0.8571 - val_loss: 0.3135 - val_accuracy: 0.8752\n",
      "Epoch 5/30\n",
      "48000/48000 [==============================] - 7s 156us/sample - loss: 0.3316 - accuracy: 0.8658 - val_loss: 0.3337 - val_accuracy: 0.8602\n",
      "Epoch 6/30\n",
      "48000/48000 [==============================] - 7s 155us/sample - loss: 0.3141 - accuracy: 0.8715 - val_loss: 0.3302 - val_accuracy: 0.8654\n",
      "Epoch 7/30\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.3010 - accuracy: 0.8769 - val_loss: 0.2911 - val_accuracy: 0.8838\n",
      "Epoch 8/30\n",
      "48000/48000 [==============================] - 8s 157us/sample - loss: 0.2839 - accuracy: 0.8846 - val_loss: 0.3099 - val_accuracy: 0.8739\n",
      "Epoch 9/30\n",
      "48000/48000 [==============================] - 7s 156us/sample - loss: 0.2719 - accuracy: 0.8903 - val_loss: 0.3141 - val_accuracy: 0.8707\n",
      "Epoch 10/30\n",
      "48000/48000 [==============================] - 7s 155us/sample - loss: 0.2677 - accuracy: 0.8918 - val_loss: 0.3015 - val_accuracy: 0.8777\n",
      "Epoch 11/30\n",
      "48000/48000 [==============================] - 7s 152us/sample - loss: 0.2571 - accuracy: 0.8949 - val_loss: 0.2958 - val_accuracy: 0.8820\n",
      "Epoch 12/30\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.2476 - accuracy: 0.8994 - val_loss: 0.2896 - val_accuracy: 0.8870\n",
      "Epoch 13/30\n",
      "48000/48000 [==============================] - 7s 155us/sample - loss: 0.2430 - accuracy: 0.9025 - val_loss: 0.2895 - val_accuracy: 0.8863\n",
      "Epoch 14/30\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.2347 - accuracy: 0.9058 - val_loss: 0.2981 - val_accuracy: 0.8811\n",
      "Epoch 15/30\n",
      "48000/48000 [==============================] - 7s 149us/sample - loss: 0.2261 - accuracy: 0.9084 - val_loss: 0.2938 - val_accuracy: 0.8863\n",
      "Epoch 16/30\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.2231 - accuracy: 0.9095 - val_loss: 0.2891 - val_accuracy: 0.8849\n",
      "Epoch 17/30\n",
      "48000/48000 [==============================] - 7s 155us/sample - loss: 0.2127 - accuracy: 0.9120 - val_loss: 0.2898 - val_accuracy: 0.8874\n",
      "Epoch 18/30\n",
      "48000/48000 [==============================] - 7s 155us/sample - loss: 0.2081 - accuracy: 0.9170 - val_loss: 0.2942 - val_accuracy: 0.8858\n",
      "Epoch 19/30\n",
      "48000/48000 [==============================] - 7s 152us/sample - loss: 0.2062 - accuracy: 0.9163 - val_loss: 0.2828 - val_accuracy: 0.8909\n",
      "Epoch 20/30\n",
      "48000/48000 [==============================] - 7s 155us/sample - loss: 0.1977 - accuracy: 0.9200 - val_loss: 0.2975 - val_accuracy: 0.8883\n",
      "Epoch 21/30\n",
      "48000/48000 [==============================] - 7s 155us/sample - loss: 0.1946 - accuracy: 0.9216 - val_loss: 0.3084 - val_accuracy: 0.8798\n",
      "Epoch 22/30\n",
      "48000/48000 [==============================] - 7s 156us/sample - loss: 0.1914 - accuracy: 0.9226 - val_loss: 0.3239 - val_accuracy: 0.8779\n",
      "Epoch 23/30\n",
      "48000/48000 [==============================] - 7s 153us/sample - loss: 0.1867 - accuracy: 0.9233 - val_loss: 0.3149 - val_accuracy: 0.8863\n",
      "Epoch 24/30\n",
      "48000/48000 [==============================] - 7s 153us/sample - loss: 0.1857 - accuracy: 0.9259 - val_loss: 0.3268 - val_accuracy: 0.8794\n",
      "Epoch 25/30\n",
      "48000/48000 [==============================] - 7s 156us/sample - loss: 0.1831 - accuracy: 0.9269 - val_loss: 0.3198 - val_accuracy: 0.8824\n",
      "Epoch 26/30\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.1792 - accuracy: 0.9283 - val_loss: 0.3002 - val_accuracy: 0.8925\n",
      "Epoch 27/30\n",
      "48000/48000 [==============================] - 7s 152us/sample - loss: 0.1743 - accuracy: 0.9301 - val_loss: 0.3059 - val_accuracy: 0.8886\n",
      "Epoch 28/30\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.1699 - accuracy: 0.9312 - val_loss: 0.3064 - val_accuracy: 0.8888\n",
      "Epoch 29/30\n",
      "48000/48000 [==============================] - 7s 156us/sample - loss: 0.1683 - accuracy: 0.9320 - val_loss: 0.3213 - val_accuracy: 0.8851\n",
      "Epoch 30/30\n",
      "   32/48000 [..............................] - ETA: 11s - loss: 0.0993 - accuracy: 0.9375"
     ]
    }
   ],
   "source": [
    "CNN1 = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "CNN1.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "historyCNN1 = CNN1.fit(X_train, y_train, epochs = 30, validation_data = (X_val, y_val))\n",
    "acc_plot(historyCNN1.history, 'CNN1')\n",
    "gen_csv(CNN1, 'CNN1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(28,28,1)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples\n",
      "Epoch 1/40\n",
      "INFO:tensorflow:batch_all_reduce: 24 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 24 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "48000/48000 [==============================] - 42s 878us/sample - loss: 0.8456 - accuracy: 0.6759\n",
      "Epoch 2/40\n",
      "48000/48000 [==============================] - 12s 240us/sample - loss: 0.6095 - accuracy: 0.7552\n",
      "Epoch 3/40\n",
      "48000/48000 [==============================] - 11s 230us/sample - loss: 0.5439 - accuracy: 0.7822\n",
      "Epoch 4/40\n",
      "48000/48000 [==============================] - 10s 215us/sample - loss: 0.4942 - accuracy: 0.8028\n",
      "Epoch 5/40\n",
      "48000/48000 [==============================] - 10s 211us/sample - loss: 0.4595 - accuracy: 0.8204\n",
      "Epoch 6/40\n",
      "48000/48000 [==============================] - 10s 217us/sample - loss: 0.4374 - accuracy: 0.8287\n",
      "Epoch 7/40\n",
      "48000/48000 [==============================] - 10s 213us/sample - loss: 0.4148 - accuracy: 0.8386\n",
      "Epoch 8/40\n",
      "48000/48000 [==============================] - 10s 218us/sample - loss: 0.3968 - accuracy: 0.8452\n",
      "Epoch 9/40\n",
      "48000/48000 [==============================] - 10s 214us/sample - loss: 0.3789 - accuracy: 0.8531\n",
      "Epoch 10/40\n",
      "48000/48000 [==============================] - 10s 215us/sample - loss: 0.3734 - accuracy: 0.8554\n",
      "Epoch 11/40\n",
      "48000/48000 [==============================] - 10s 214us/sample - loss: 0.3587 - accuracy: 0.8609\n",
      "Epoch 12/40\n",
      "48000/48000 [==============================] - 10s 216us/sample - loss: 0.3482 - accuracy: 0.8659\n",
      "Epoch 13/40\n",
      "48000/48000 [==============================] - 10s 213us/sample - loss: 0.3564 - accuracy: 0.8622\n",
      "Epoch 14/40\n",
      "48000/48000 [==============================] - 10s 215us/sample - loss: 0.3400 - accuracy: 0.8692\n",
      "Epoch 15/40\n",
      "48000/48000 [==============================] - 10s 214us/sample - loss: 0.3283 - accuracy: 0.8739\n",
      "Epoch 16/40\n",
      "48000/48000 [==============================] - 10s 214us/sample - loss: 0.3225 - accuracy: 0.8768\n",
      "Epoch 17/40\n",
      "48000/48000 [==============================] - 10s 216us/sample - loss: 0.3089 - accuracy: 0.8823\n",
      "Epoch 18/40\n",
      "48000/48000 [==============================] - 10s 216us/sample - loss: 0.3047 - accuracy: 0.8828\n",
      "Epoch 19/40\n",
      "48000/48000 [==============================] - 10s 212us/sample - loss: 0.2915 - accuracy: 0.8880\n",
      "Epoch 20/40\n",
      "48000/48000 [==============================] - 10s 216us/sample - loss: 0.2914 - accuracy: 0.8865\n",
      "Epoch 21/40\n",
      "48000/48000 [==============================] - 10s 215us/sample - loss: 0.2700 - accuracy: 0.8954\n",
      "Epoch 22/40\n",
      "48000/48000 [==============================] - 10s 213us/sample - loss: 0.2657 - accuracy: 0.8981\n",
      "Epoch 23/40\n",
      "48000/48000 [==============================] - 10s 217us/sample - loss: 0.2621 - accuracy: 0.8990\n",
      "Epoch 24/40\n",
      "48000/48000 [==============================] - 10s 216us/sample - loss: 0.2810 - accuracy: 0.8922\n",
      "Epoch 25/40\n",
      "48000/48000 [==============================] - 10s 214us/sample - loss: 0.2701 - accuracy: 0.8967\n",
      "Epoch 26/40\n",
      "48000/48000 [==============================] - 10s 216us/sample - loss: 0.2556 - accuracy: 0.9016\n",
      "Epoch 27/40\n",
      "48000/48000 [==============================] - 10s 215us/sample - loss: 0.2452 - accuracy: 0.9050\n",
      "Epoch 28/40\n",
      "48000/48000 [==============================] - 10s 215us/sample - loss: 0.2295 - accuracy: 0.9133\n",
      "Epoch 29/40\n",
      "48000/48000 [==============================] - 10s 215us/sample - loss: 0.2344 - accuracy: 0.9106\n",
      "Epoch 30/40\n",
      "48000/48000 [==============================] - 10s 214us/sample - loss: 0.2290 - accuracy: 0.9125\n",
      "Epoch 31/40\n",
      "48000/48000 [==============================] - 10s 214us/sample - loss: 0.2226 - accuracy: 0.9158\n",
      "Epoch 32/40\n",
      "48000/48000 [==============================] - 10s 217us/sample - loss: 0.2160 - accuracy: 0.9181\n",
      "Epoch 33/40\n",
      "48000/48000 [==============================] - 10s 213us/sample - loss: 0.2189 - accuracy: 0.9171\n",
      "Epoch 34/40\n",
      "48000/48000 [==============================] - 10s 215us/sample - loss: 0.2120 - accuracy: 0.9206\n",
      "Epoch 35/40\n",
      "48000/48000 [==============================] - 10s 216us/sample - loss: 0.2082 - accuracy: 0.9202\n",
      "Epoch 36/40\n",
      "48000/48000 [==============================] - 10s 215us/sample - loss: 0.1921 - accuracy: 0.9257\n",
      "Epoch 37/40\n",
      "48000/48000 [==============================] - 10s 214us/sample - loss: 0.1993 - accuracy: 0.9247\n",
      "Epoch 38/40\n",
      "48000/48000 [==============================] - 10s 215us/sample - loss: 0.1969 - accuracy: 0.9256\n",
      "Epoch 39/40\n",
      "48000/48000 [==============================] - 10s 216us/sample - loss: 0.1978 - accuracy: 0.9257\n",
      "Epoch 40/40\n",
      "48000/48000 [==============================] - 10s 213us/sample - loss: 0.2023 - accuracy: 0.9229\n",
      "12000/12000 [==============================] - 5s 394us/sample - loss: 0.2691 - accuracy: 0.8970\n",
      "Accuracy: 0.897\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=40, batch_size=128)\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 375 steps, validate on 12000 samples\n",
      "Epoch 1/40\n",
      "375/375 [==============================] - 23s 63ms/step - loss: 0.6649 - accuracy: 0.7512 - val_loss: 0.3261 - val_accuracy: 0.8732\n",
      "Epoch 2/40\n",
      "375/375 [==============================] - 21s 55ms/step - loss: 0.5207 - accuracy: 0.7897 - val_loss: 0.3525 - val_accuracy: 0.8547\n",
      "Epoch 3/40\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 0.4928 - accuracy: 0.8031 - val_loss: 0.3338 - val_accuracy: 0.8637\n",
      "Epoch 4/40\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.4783 - accuracy: 0.8084 - val_loss: 0.4013 - val_accuracy: 0.8298\n",
      "Epoch 5/40\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 0.4631 - accuracy: 0.8143 - val_loss: 0.6324 - val_accuracy: 0.7389\n",
      "Epoch 6/40\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 0.4547 - accuracy: 0.8170 - val_loss: 0.3197 - val_accuracy: 0.8668\n",
      "Epoch 7/40\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.4453 - accuracy: 0.8206 - val_loss: 0.3496 - val_accuracy: 0.8581\n",
      "Epoch 8/40\n",
      "375/375 [==============================] - 20s 53ms/step - loss: 0.4388 - accuracy: 0.8221 - val_loss: 0.3143 - val_accuracy: 0.8717\n",
      "Epoch 9/40\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.4376 - accuracy: 0.8231 - val_loss: 0.4014 - val_accuracy: 0.8280\n",
      "Epoch 10/40\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 0.4267 - accuracy: 0.8282 - val_loss: 0.4004 - val_accuracy: 0.8307\n",
      "Epoch 11/40\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.4213 - accuracy: 0.8292 - val_loss: 0.4670 - val_accuracy: 0.7976\n",
      "Epoch 12/40\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 0.4198 - accuracy: 0.8310 - val_loss: 0.7995 - val_accuracy: 0.7047\n",
      "Epoch 13/40\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.4199 - accuracy: 0.8310 - val_loss: 0.6813 - val_accuracy: 0.7310\n",
      "Epoch 14/40\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.4118 - accuracy: 0.8340 - val_loss: 0.7324 - val_accuracy: 0.7094\n",
      "Epoch 15/40\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 0.4080 - accuracy: 0.8346 - val_loss: 0.4586 - val_accuracy: 0.8042\n",
      "Epoch 16/40\n",
      "375/375 [==============================] - 21s 55ms/step - loss: 0.4039 - accuracy: 0.8365 - val_loss: 0.4118 - val_accuracy: 0.8252\n",
      "Epoch 17/40\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.3989 - accuracy: 0.8367 - val_loss: 0.4268 - val_accuracy: 0.8157\n",
      "Epoch 18/40\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 0.3984 - accuracy: 0.8392 - val_loss: 0.4781 - val_accuracy: 0.7966\n",
      "Epoch 19/40\n",
      "375/375 [==============================] - 26s 69ms/step - loss: 0.3938 - accuracy: 0.8388 - val_loss: 0.4225 - val_accuracy: 0.8142\n",
      "Epoch 20/40\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 0.3950 - accuracy: 0.8389 - val_loss: 0.3886 - val_accuracy: 0.8293\n",
      "Epoch 21/40\n",
      "375/375 [==============================] - 24s 63ms/step - loss: 0.3894 - accuracy: 0.8430 - val_loss: 0.4141 - val_accuracy: 0.8250\n",
      "Epoch 22/40\n",
      "375/375 [==============================] - 20s 53ms/step - loss: 0.3907 - accuracy: 0.8420 - val_loss: 0.4415 - val_accuracy: 0.8083\n",
      "Epoch 23/40\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.3859 - accuracy: 0.8432 - val_loss: 0.6980 - val_accuracy: 0.7316\n",
      "Epoch 24/40\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.3797 - accuracy: 0.8465 - val_loss: 0.7241 - val_accuracy: 0.7229\n",
      "Epoch 25/40\n",
      "375/375 [==============================] - 21s 55ms/step - loss: 0.3816 - accuracy: 0.8464 - val_loss: 0.3788 - val_accuracy: 0.8385\n",
      "Epoch 26/40\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.3748 - accuracy: 0.8471 - val_loss: 0.4309 - val_accuracy: 0.8132\n",
      "Epoch 27/40\n",
      "375/375 [==============================] - 21s 55ms/step - loss: 0.3758 - accuracy: 0.8456 - val_loss: 0.8617 - val_accuracy: 0.6983\n",
      "Epoch 28/40\n",
      "375/375 [==============================] - 26s 70ms/step - loss: 0.3778 - accuracy: 0.8471 - val_loss: 0.4724 - val_accuracy: 0.7988\n",
      "Epoch 29/40\n",
      "375/375 [==============================] - 25s 67ms/step - loss: 0.3715 - accuracy: 0.8473 - val_loss: 0.4421 - val_accuracy: 0.8111\n",
      "Epoch 30/40\n",
      "375/375 [==============================] - 26s 68ms/step - loss: 0.3750 - accuracy: 0.8461 - val_loss: 0.4279 - val_accuracy: 0.8167\n",
      "Epoch 31/40\n",
      "375/375 [==============================] - 27s 71ms/step - loss: 0.3682 - accuracy: 0.8516 - val_loss: 0.4974 - val_accuracy: 0.7922\n",
      "Epoch 32/40\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 0.3680 - accuracy: 0.8523 - val_loss: 0.5237 - val_accuracy: 0.7815\n",
      "Epoch 33/40\n",
      "375/375 [==============================] - 25s 66ms/step - loss: 0.3641 - accuracy: 0.8543 - val_loss: 0.5711 - val_accuracy: 0.7768\n",
      "Epoch 34/40\n",
      "375/375 [==============================] - 25s 68ms/step - loss: 0.3607 - accuracy: 0.8537 - val_loss: 0.5481 - val_accuracy: 0.7767\n",
      "Epoch 35/40\n",
      "375/375 [==============================] - 26s 69ms/step - loss: 0.3610 - accuracy: 0.8537 - val_loss: 0.4310 - val_accuracy: 0.8139\n",
      "Epoch 36/40\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.3644 - accuracy: 0.8502 - val_loss: 0.3289 - val_accuracy: 0.8587\n",
      "Epoch 37/40\n",
      "375/375 [==============================] - 20s 53ms/step - loss: 0.3589 - accuracy: 0.8547 - val_loss: 0.6416 - val_accuracy: 0.7483\n",
      "Epoch 38/40\n",
      "375/375 [==============================] - 26s 70ms/step - loss: 0.3548 - accuracy: 0.8556 - val_loss: 0.5931 - val_accuracy: 0.7673\n",
      "Epoch 39/40\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.3516 - accuracy: 0.8568 - val_loss: 0.3865 - val_accuracy: 0.8396\n",
      "Epoch 40/40\n",
      "375/375 [==============================] - 19s 50ms/step - loss: 0.3534 - accuracy: 0.8562 - val_loss: 0.4077 - val_accuracy: 0.8264\n",
      "12000/12000 [==============================] - 1s 118us/sample - loss: 0.4077 - accuracy: 0.8264\n",
      "Loss: 0.4077\n",
      "Accuracy: 0.8264\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rotation_range = 8, zoom_range = 0.1, shear_range = 0.3, width_shift_range=0.08, height_shift_range=0.08, vertical_flip=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size = 128), epochs = 40, validation_data = (X_test, y_test), steps_per_epoch=X_train.shape[0] // 128, callbacks = [reduce_lr])\n",
    "score = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Loss: {:.4f}'.format(score[0]))\n",
    "print('Accuracy: {:.4f}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(28,28,1)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "    Dropout(0.5),\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Conv2D(filters=256, kernel_size=(3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 8s 174us/sample - loss: 0.3455 - accuracy: 0.8625 - val_loss: 0.2962 - val_accuracy: 0.8742\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 8s 165us/sample - loss: 0.3384 - accuracy: 0.8649 - val_loss: 0.4136 - val_accuracy: 0.8307\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.3269 - accuracy: 0.8704 - val_loss: 0.2907 - val_accuracy: 0.8819\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 8s 165us/sample - loss: 0.3165 - accuracy: 0.8746 - val_loss: 0.2683 - val_accuracy: 0.8883\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 8s 162us/sample - loss: 0.3184 - accuracy: 0.8736 - val_loss: 0.2603 - val_accuracy: 0.8951\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 8s 166us/sample - loss: 0.3105 - accuracy: 0.8750 - val_loss: 0.4409 - val_accuracy: 0.8234\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.2999 - accuracy: 0.8806 - val_loss: 0.3219 - val_accuracy: 0.8682\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.2952 - accuracy: 0.8818 - val_loss: 0.3765 - val_accuracy: 0.8480\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.2888 - accuracy: 0.8851 - val_loss: 0.2827 - val_accuracy: 0.8829\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.2845 - accuracy: 0.8875 - val_loss: 0.4459 - val_accuracy: 0.8241\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 8s 165us/sample - loss: 0.2825 - accuracy: 0.8875 - val_loss: 0.2717 - val_accuracy: 0.8895\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 8s 167us/sample - loss: 0.2733 - accuracy: 0.8911 - val_loss: 0.2935 - val_accuracy: 0.8824\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.2659 - accuracy: 0.8935 - val_loss: 0.2624 - val_accuracy: 0.8955\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.2634 - accuracy: 0.8953 - val_loss: 0.3654 - val_accuracy: 0.8553\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 8s 167us/sample - loss: 0.2556 - accuracy: 0.8986 - val_loss: 0.2570 - val_accuracy: 0.8951\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 8s 165us/sample - loss: 0.2485 - accuracy: 0.9015 - val_loss: 0.2452 - val_accuracy: 0.9027\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 8s 166us/sample - loss: 0.2436 - accuracy: 0.9034 - val_loss: 0.3099 - val_accuracy: 0.8779\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 8s 165us/sample - loss: 0.2420 - accuracy: 0.9054 - val_loss: 0.2895 - val_accuracy: 0.8855\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.2434 - accuracy: 0.9034 - val_loss: 0.2684 - val_accuracy: 0.8938\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.2284 - accuracy: 0.9102 - val_loss: 0.2619 - val_accuracy: 0.8974\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 8s 162us/sample - loss: 0.2241 - accuracy: 0.9109 - val_loss: 0.2859 - val_accuracy: 0.8867\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 8s 165us/sample - loss: 0.2216 - accuracy: 0.9138 - val_loss: 0.2518 - val_accuracy: 0.9011\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.2180 - accuracy: 0.9153 - val_loss: 0.3787 - val_accuracy: 0.8551\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 8s 162us/sample - loss: 0.2130 - accuracy: 0.9147 - val_loss: 0.4058 - val_accuracy: 0.8493\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 8s 165us/sample - loss: 0.2069 - accuracy: 0.9176 - val_loss: 0.2882 - val_accuracy: 0.8891\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 8s 166us/sample - loss: 0.2030 - accuracy: 0.9203 - val_loss: 0.2504 - val_accuracy: 0.9026\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 8s 165us/sample - loss: 0.1983 - accuracy: 0.9217 - val_loss: 0.2862 - val_accuracy: 0.8923\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 8s 165us/sample - loss: 0.1897 - accuracy: 0.9263 - val_loss: 0.2842 - val_accuracy: 0.8910\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 8s 167us/sample - loss: 0.2016 - accuracy: 0.9215 - val_loss: 0.2585 - val_accuracy: 0.8984\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 8s 166us/sample - loss: 0.1885 - accuracy: 0.9272 - val_loss: 0.2518 - val_accuracy: 0.9033\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.1858 - accuracy: 0.9274 - val_loss: 0.2815 - val_accuracy: 0.8967\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.1784 - accuracy: 0.9313 - val_loss: 0.3002 - val_accuracy: 0.8891\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.1672 - accuracy: 0.9348 - val_loss: 0.2957 - val_accuracy: 0.8940\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.1787 - accuracy: 0.9306 - val_loss: 0.3181 - val_accuracy: 0.8822\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.1720 - accuracy: 0.9330 - val_loss: 0.3110 - val_accuracy: 0.8817\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.1661 - accuracy: 0.9346 - val_loss: 0.2875 - val_accuracy: 0.8928\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 8s 165us/sample - loss: 0.1613 - accuracy: 0.9374 - val_loss: 0.4459 - val_accuracy: 0.8545\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.1573 - accuracy: 0.9396 - val_loss: 0.2757 - val_accuracy: 0.8976\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 8s 162us/sample - loss: 0.1545 - accuracy: 0.9406 - val_loss: 0.2943 - val_accuracy: 0.8967\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 8s 169us/sample - loss: 0.1542 - accuracy: 0.9400 - val_loss: 0.4682 - val_accuracy: 0.8486\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.1505 - accuracy: 0.9415 - val_loss: 0.3745 - val_accuracy: 0.8727\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.1537 - accuracy: 0.9422 - val_loss: 0.2869 - val_accuracy: 0.8975\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.1416 - accuracy: 0.9458 - val_loss: 0.2733 - val_accuracy: 0.9047\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.1442 - accuracy: 0.9455 - val_loss: 0.3273 - val_accuracy: 0.8905\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 8s 168us/sample - loss: 0.1412 - accuracy: 0.9455 - val_loss: 0.3243 - val_accuracy: 0.8876\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.1370 - accuracy: 0.9481 - val_loss: 0.3886 - val_accuracy: 0.8723\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.1382 - accuracy: 0.9474 - val_loss: 0.2941 - val_accuracy: 0.8956\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 8s 163us/sample - loss: 0.1385 - accuracy: 0.9480 - val_loss: 0.2713 - val_accuracy: 0.9033\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 8s 164us/sample - loss: 0.1281 - accuracy: 0.9520 - val_loss: 0.2917 - val_accuracy: 0.9000\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 8s 162us/sample - loss: 0.1339 - accuracy: 0.9488 - val_loss: 0.2718 - val_accuracy: 0.9070\n",
      "12000/12000 [==============================] - 2s 145us/sample - loss: 0.2718 - accuracy: 0.9070\n",
      "Accuracy: 0.907\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=128, validation_data = (X_test, y_test), callbacks = [reduce_lr])\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 3959 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 7s 154us/sample - loss: 0.8056 - accuracy: 0.6500 - val_loss: 0.4770 - val_accuracy: 0.8035\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.5500 - accuracy: 0.7766 - val_loss: 0.4159 - val_accuracy: 0.8272\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.4891 - accuracy: 0.8031 - val_loss: 0.4310 - val_accuracy: 0.8126\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.4538 - accuracy: 0.8152 - val_loss: 0.3531 - val_accuracy: 0.8588\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.4248 - accuracy: 0.8275 - val_loss: 0.3564 - val_accuracy: 0.8535\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.4015 - accuracy: 0.8397 - val_loss: 0.3329 - val_accuracy: 0.8702\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.3875 - accuracy: 0.8435 - val_loss: 0.3508 - val_accuracy: 0.8618\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.3767 - accuracy: 0.8490 - val_loss: 0.3304 - val_accuracy: 0.8628\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 4s 94us/sample - loss: 0.3620 - accuracy: 0.8545 - val_loss: 0.3124 - val_accuracy: 0.8714\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.3671 - accuracy: 0.8535 - val_loss: 0.2881 - val_accuracy: 0.8911\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.3490 - accuracy: 0.8603 - val_loss: 0.2911 - val_accuracy: 0.8873\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.3395 - accuracy: 0.8643 - val_loss: 0.2987 - val_accuracy: 0.8808\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.3338 - accuracy: 0.8667 - val_loss: 0.2841 - val_accuracy: 0.8876\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.3324 - accuracy: 0.8671 - val_loss: 0.2787 - val_accuracy: 0.8962\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.3239 - accuracy: 0.8689 - val_loss: 0.2754 - val_accuracy: 0.8863\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.3187 - accuracy: 0.8729 - val_loss: 0.3270 - val_accuracy: 0.8596\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.3172 - accuracy: 0.8720 - val_loss: 0.2757 - val_accuracy: 0.8904\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.3016 - accuracy: 0.8792 - val_loss: 0.2708 - val_accuracy: 0.8937\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.3084 - accuracy: 0.8780 - val_loss: 0.2607 - val_accuracy: 0.8939\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.3044 - accuracy: 0.8784 - val_loss: 0.2709 - val_accuracy: 0.8876\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.3021 - accuracy: 0.8805 - val_loss: 0.2877 - val_accuracy: 0.8896\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.2965 - accuracy: 0.8832 - val_loss: 0.2679 - val_accuracy: 0.8954\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.2944 - accuracy: 0.8822 - val_loss: 0.2661 - val_accuracy: 0.8909\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.2881 - accuracy: 0.8842 - val_loss: 0.2514 - val_accuracy: 0.9002\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.2890 - accuracy: 0.8851 - val_loss: 0.2735 - val_accuracy: 0.8853\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.2859 - accuracy: 0.8854 - val_loss: 0.2662 - val_accuracy: 0.8957\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.2885 - accuracy: 0.8851 - val_loss: 0.2596 - val_accuracy: 0.8962\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.2817 - accuracy: 0.8880 - val_loss: 0.2467 - val_accuracy: 0.8969\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.2726 - accuracy: 0.8891 - val_loss: 0.2749 - val_accuracy: 0.8909\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.2760 - accuracy: 0.8888 - val_loss: 0.2699 - val_accuracy: 0.8916\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.2735 - accuracy: 0.8909 - val_loss: 0.2760 - val_accuracy: 0.8899\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.2695 - accuracy: 0.8920 - val_loss: 0.2600 - val_accuracy: 0.9007\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.2709 - accuracy: 0.8911 - val_loss: 0.2693 - val_accuracy: 0.8942\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.2650 - accuracy: 0.8938 - val_loss: 0.2751 - val_accuracy: 0.8891\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.2655 - accuracy: 0.8935 - val_loss: 0.2582 - val_accuracy: 0.8914\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.2619 - accuracy: 0.8958 - val_loss: 0.2449 - val_accuracy: 0.9081\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.2614 - accuracy: 0.8970 - val_loss: 0.2621 - val_accuracy: 0.9012\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.2608 - accuracy: 0.8965 - val_loss: 0.2492 - val_accuracy: 0.9045\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.2534 - accuracy: 0.8988 - val_loss: 0.2707 - val_accuracy: 0.8919\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.2556 - accuracy: 0.8967 - val_loss: 0.2357 - val_accuracy: 0.9088\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.2518 - accuracy: 0.9001 - val_loss: 0.2846 - val_accuracy: 0.8833\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.2575 - accuracy: 0.8983 - val_loss: 0.2412 - val_accuracy: 0.9078\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.2509 - accuracy: 0.9015 - val_loss: 0.2430 - val_accuracy: 0.9086\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.2587 - accuracy: 0.8974 - val_loss: 0.2612 - val_accuracy: 0.8947\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.2532 - accuracy: 0.8994 - val_loss: 0.2507 - val_accuracy: 0.9012\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.2415 - accuracy: 0.9045 - val_loss: 0.2465 - val_accuracy: 0.9043\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.2531 - accuracy: 0.9007 - val_loss: 0.2394 - val_accuracy: 0.9091\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.2458 - accuracy: 0.9030 - val_loss: 0.2360 - val_accuracy: 0.9081\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.2433 - accuracy: 0.9057 - val_loss: 0.2548 - val_accuracy: 0.8990\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.2466 - accuracy: 0.9029 - val_loss: 0.2333 - val_accuracy: 0.9126\n",
      "8041/8041 [==============================] - 1s 135us/sample - loss: 0.2494 - accuracy: 0.8986\n",
      "Accuracy: 0.899\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(28,28,1)),\n",
    "#     BatchNormalization(),\n",
    "#     Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "#     BatchNormalization(),\n",
    "#     Dropout(0.5),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "    Dropout(0.5),\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "#     BatchNormalization(),\n",
    "#     Dropout(0.5),\n",
    "    Conv2D(filters=256, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(3, 3)),\n",
    "#     BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "#     BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "#     BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "model3.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model3.fit(X_train, y_train, epochs=50, batch_size=128, validation_data = (X_val, y_val))\n",
    "loss, acc = model3.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 3959 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 14s 300us/sample - loss: 0.9223 - accuracy: 0.6424 - val_loss: 39.5883 - val_accuracy: 0.2008\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 13s 262us/sample - loss: 0.6906 - accuracy: 0.7178 - val_loss: 0.8555 - val_accuracy: 0.6449\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 13s 261us/sample - loss: 0.5824 - accuracy: 0.7648 - val_loss: 1.0548 - val_accuracy: 0.5580\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 13s 264us/sample - loss: 0.5441 - accuracy: 0.7801 - val_loss: 0.4859 - val_accuracy: 0.8141\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 13s 264us/sample - loss: 0.5152 - accuracy: 0.7928 - val_loss: 0.8056 - val_accuracy: 0.7148\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 13s 264us/sample - loss: 0.4929 - accuracy: 0.7999 - val_loss: 0.4084 - val_accuracy: 0.8340\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 13s 262us/sample - loss: 0.4744 - accuracy: 0.8118 - val_loss: 0.4237 - val_accuracy: 0.8348\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 13s 266us/sample - loss: 0.4533 - accuracy: 0.8178 - val_loss: 0.5138 - val_accuracy: 0.7805\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 13s 266us/sample - loss: 0.5407 - accuracy: 0.7851 - val_loss: 0.5036 - val_accuracy: 0.7790\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 13s 263us/sample - loss: 0.4552 - accuracy: 0.8174 - val_loss: 0.5607 - val_accuracy: 0.7547\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 13s 266us/sample - loss: 0.4882 - accuracy: 0.8071 - val_loss: 0.3977 - val_accuracy: 0.8404\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 13s 268us/sample - loss: 0.4392 - accuracy: 0.8245 - val_loss: 0.4017 - val_accuracy: 0.8406\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 13s 265us/sample - loss: 0.4195 - accuracy: 0.8316 - val_loss: 0.4101 - val_accuracy: 0.8252\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 13s 268us/sample - loss: 0.4073 - accuracy: 0.8358 - val_loss: 0.3555 - val_accuracy: 0.8525\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 13s 266us/sample - loss: 0.3881 - accuracy: 0.8453 - val_loss: 0.4227 - val_accuracy: 0.8234\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 13s 264us/sample - loss: 0.3946 - accuracy: 0.8431 - val_loss: 0.4174 - val_accuracy: 0.8626\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 13s 264us/sample - loss: 0.4109 - accuracy: 0.8372 - val_loss: 0.3316 - val_accuracy: 0.8671\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 13s 266us/sample - loss: 0.3848 - accuracy: 0.8445 - val_loss: 0.6658 - val_accuracy: 0.7338\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 13s 264us/sample - loss: 0.3722 - accuracy: 0.8501 - val_loss: 0.3582 - val_accuracy: 0.8565\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 13s 267us/sample - loss: 0.3654 - accuracy: 0.8538 - val_loss: 0.3207 - val_accuracy: 0.8724\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 13s 266us/sample - loss: 0.3637 - accuracy: 0.8546 - val_loss: 0.3488 - val_accuracy: 0.8606\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 13s 267us/sample - loss: 0.3614 - accuracy: 0.8546 - val_loss: 0.9545 - val_accuracy: 0.8477\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 13s 265us/sample - loss: 0.3522 - accuracy: 0.8592 - val_loss: 0.3215 - val_accuracy: 0.8644\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 13s 264us/sample - loss: 0.3434 - accuracy: 0.8622 - val_loss: 0.3132 - val_accuracy: 0.8750\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 13s 265us/sample - loss: 0.3407 - accuracy: 0.8638 - val_loss: 0.4108 - val_accuracy: 0.8287\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 13s 266us/sample - loss: 0.3367 - accuracy: 0.8650 - val_loss: 0.4913 - val_accuracy: 0.8058\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 13s 265us/sample - loss: 0.3311 - accuracy: 0.8658 - val_loss: 0.3009 - val_accuracy: 0.8881\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 13s 265us/sample - loss: 0.3287 - accuracy: 0.8667 - val_loss: 1.1620 - val_accuracy: 0.8636\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 13s 265us/sample - loss: 0.3260 - accuracy: 0.8702 - val_loss: 0.3549 - val_accuracy: 0.8464\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 13s 264us/sample - loss: 0.3282 - accuracy: 0.8677 - val_loss: 0.2763 - val_accuracy: 0.8889\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 13s 265us/sample - loss: 0.3183 - accuracy: 0.8729 - val_loss: 0.3997 - val_accuracy: 0.8621\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 13s 269us/sample - loss: 0.3154 - accuracy: 0.8734 - val_loss: 0.3640 - val_accuracy: 0.8553\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 13s 265us/sample - loss: 0.3060 - accuracy: 0.8785 - val_loss: 0.5386 - val_accuracy: 0.7967\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 13s 265us/sample - loss: 0.3087 - accuracy: 0.8766 - val_loss: 0.3872 - val_accuracy: 0.8444\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 13s 265us/sample - loss: 0.2960 - accuracy: 0.8818 - val_loss: 0.2792 - val_accuracy: 0.8909\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 13s 265us/sample - loss: 0.2965 - accuracy: 0.8810 - val_loss: 0.2647 - val_accuracy: 0.8990\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 13s 269us/sample - loss: 0.2981 - accuracy: 0.8800 - val_loss: 0.2726 - val_accuracy: 0.8916\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 13s 267us/sample - loss: 0.2847 - accuracy: 0.8845 - val_loss: 0.3467 - val_accuracy: 0.8621\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 13s 265us/sample - loss: 0.2855 - accuracy: 0.8856 - val_loss: 0.2629 - val_accuracy: 0.8995\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 13s 266us/sample - loss: 0.2886 - accuracy: 0.8838 - val_loss: 0.3774 - val_accuracy: 0.8848\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 13s 268us/sample - loss: 0.2895 - accuracy: 0.8844 - val_loss: 0.2815 - val_accuracy: 0.8881\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 13s 266us/sample - loss: 0.2742 - accuracy: 0.8894 - val_loss: 0.2597 - val_accuracy: 0.8995\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 13s 265us/sample - loss: 0.2716 - accuracy: 0.8913 - val_loss: 0.2582 - val_accuracy: 0.8942\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 13s 265us/sample - loss: 0.2624 - accuracy: 0.8938 - val_loss: 0.2848 - val_accuracy: 0.8876\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 13s 265us/sample - loss: 0.2680 - accuracy: 0.8929 - val_loss: 0.3477 - val_accuracy: 0.8641\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 13s 267us/sample - loss: 0.2606 - accuracy: 0.8956 - val_loss: 0.2410 - val_accuracy: 0.9033\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 13s 266us/sample - loss: 0.2571 - accuracy: 0.8994 - val_loss: 1.1340 - val_accuracy: 0.8881\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 13s 264us/sample - loss: 0.2629 - accuracy: 0.8956 - val_loss: 0.2376 - val_accuracy: 0.9063\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 13s 265us/sample - loss: 0.2523 - accuracy: 0.8980 - val_loss: 0.3279 - val_accuracy: 0.8707\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 13s 266us/sample - loss: 0.2493 - accuracy: 0.9007 - val_loss: 1.0073 - val_accuracy: 0.8659\n",
      "8041/8041 [==============================] - 2s 204us/sample - loss: 0.7096 - accuracy: 0.8598\n",
      "Accuracy: 0.860\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(28,28,1)),\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "#     MaxPool2D(pool_size=(2, 2)),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "#     MaxPool2D(pool_size=(2, 2)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "\n",
    "#     Dropout(0.5),\n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "model4.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model4.fit(X_train, y_train, epochs=50, batch_size=128, validation_data = (X_val, y_val))\n",
    "loss, acc = model4.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
