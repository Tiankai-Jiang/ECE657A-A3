{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import concatenate, Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPool2D, GlobalMaxPooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "import tensorflow.keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module(layer_in, f1, f2_in, f2_out, f3_in, f3_out, f4_out):\n",
    "    conv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(layer_in)\n",
    "    conv3 = Conv2D(f2_in, (1,1), padding='same', activation='relu')(layer_in)\n",
    "    conv3 = Conv2D(f2_out, (3,3), padding='same', activation='relu')(conv3)\n",
    "    conv5 = Conv2D(f3_in, (1,1), padding='same', activation='relu')(layer_in)\n",
    "    conv5 = Conv2D(f3_out, (5,5), padding='same', activation='relu')(conv5)\n",
    "    pool = MaxPool2D((3,3), strides=(1,1), padding='same')(layer_in)\n",
    "    pool = Conv2D(f4_out, (1,1), padding='same', activation='relu')(pool)\n",
    "    layer_out = concatenate([conv1, conv3, conv5, pool], axis=-1)\n",
    "    return layer_out\n",
    " \n",
    "# define model input\n",
    "visible = Input(shape=(64, 64, 3))\n",
    "# add inception block 1\n",
    "layer = inception_module(visible, 64, 96, 128, 16, 32, 32)\n",
    "# add inception block 1\n",
    "layer = inception_module(layer, 128, 128, 192, 32, 96, 64)\n",
    "\n",
    "for fc in [256, 128]:\n",
    "    layer = Dense(fc, activation='relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "layer = Flatten()(layer)\n",
    "predictions = Dense(5, activation='softmax')(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=visible, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 64, 64, 96)   384         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 64, 64, 16)   64          input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 64, 64, 3)    0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 64, 64, 64)   256         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 64, 64, 128)  110720      conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 64, 64, 32)   12832       conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 64, 64, 32)   128         max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 64, 64, 256)  0           conv2d_72[0][0]                  \n",
      "                                                                 conv2d_74[0][0]                  \n",
      "                                                                 conv2d_76[0][0]                  \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 64, 64, 128)  32896       concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 64, 64, 32)   8224        concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 64, 64, 256)  0           concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 64, 64, 128)  32896       concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 64, 64, 192)  221376      conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 64, 64, 96)   76896       conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 64, 64, 64)   16448       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 64, 64, 480)  0           conv2d_78[0][0]                  \n",
      "                                                                 conv2d_80[0][0]                  \n",
      "                                                                 conv2d_82[0][0]                  \n",
      "                                                                 conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 64, 64, 256)  123136      concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 64, 64, 256)  0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 64, 64, 128)  32896       dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 64, 64, 128)  0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 524288)       0           dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 5)            2621445     flatten_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,290,597\n",
      "Trainable params: 3,290,597\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv').drop(columns=['Id'])\n",
    "X = np.array(df.iloc[:, 1:])\n",
    "y = to_categorical(np.array(df.iloc[:, 0]))\n",
    "\n",
    "# Convert the training and test images into 3 channels\n",
    "X = np.dstack([X] * 3)\n",
    "# Reshape images as per the tensor format required by tensorflow\n",
    "X = X.reshape(-1, 28, 28, 3)\n",
    "X = np.asarray([img_to_array(array_to_img(im, scale=False).resize((64,64))) for im in X])\n",
    "X = X.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 6000 samples\n",
      "Epoch 1/25\n",
      "48000/48000 [==============================] - 174s 4ms/sample - loss: 0.7902 - accuracy: 0.6832 - val_loss: 0.5908 - val_accuracy: 0.7588\n",
      "Epoch 2/25\n",
      "48000/48000 [==============================] - 172s 4ms/sample - loss: 0.5306 - accuracy: 0.7805 - val_loss: 0.5199 - val_accuracy: 0.7758\n",
      "Epoch 3/25\n",
      "48000/48000 [==============================] - 172s 4ms/sample - loss: 0.4749 - accuracy: 0.8044 - val_loss: 0.5333 - val_accuracy: 0.7767\n",
      "Epoch 4/25\n",
      "48000/48000 [==============================] - 172s 4ms/sample - loss: 0.4449 - accuracy: 0.8195 - val_loss: 0.4466 - val_accuracy: 0.8217\n",
      "Epoch 5/25\n",
      "48000/48000 [==============================] - 172s 4ms/sample - loss: 0.4201 - accuracy: 0.8295 - val_loss: 0.4504 - val_accuracy: 0.8125\n",
      "Epoch 6/25\n",
      "48000/48000 [==============================] - 172s 4ms/sample - loss: 0.3857 - accuracy: 0.8448 - val_loss: 0.4507 - val_accuracy: 0.8170\n",
      "Epoch 7/25\n",
      "48000/48000 [==============================] - 172s 4ms/sample - loss: 0.3665 - accuracy: 0.8514 - val_loss: 0.4304 - val_accuracy: 0.8247\n",
      "Epoch 8/25\n",
      "48000/48000 [==============================] - 172s 4ms/sample - loss: 0.3420 - accuracy: 0.8622 - val_loss: 0.4362 - val_accuracy: 0.8225\n",
      "Epoch 9/25\n",
      "48000/48000 [==============================] - 172s 4ms/sample - loss: 0.3175 - accuracy: 0.8713 - val_loss: 0.4140 - val_accuracy: 0.8350\n",
      "Epoch 10/25\n",
      "48000/48000 [==============================] - 172s 4ms/sample - loss: 0.2968 - accuracy: 0.8800 - val_loss: 0.4347 - val_accuracy: 0.8310\n",
      "Epoch 11/25\n",
      "48000/48000 [==============================] - 172s 4ms/sample - loss: 0.2711 - accuracy: 0.8915 - val_loss: 0.4357 - val_accuracy: 0.8328\n",
      "Epoch 12/25\n",
      "48000/48000 [==============================] - 172s 4ms/sample - loss: 0.2487 - accuracy: 0.9007 - val_loss: 0.4469 - val_accuracy: 0.8343\n",
      "Epoch 13/25\n",
      "48000/48000 [==============================] - 171s 4ms/sample - loss: 0.2406 - accuracy: 0.9034 - val_loss: 0.4867 - val_accuracy: 0.8173\n",
      "Epoch 14/25\n",
      "48000/48000 [==============================] - 171s 4ms/sample - loss: 0.2122 - accuracy: 0.9158 - val_loss: 0.4667 - val_accuracy: 0.8363\n",
      "Epoch 15/25\n",
      "48000/48000 [==============================] - 171s 4ms/sample - loss: 0.1952 - accuracy: 0.9226 - val_loss: 0.4958 - val_accuracy: 0.8272\n",
      "Epoch 16/25\n",
      "48000/48000 [==============================] - 171s 4ms/sample - loss: 0.1837 - accuracy: 0.9273 - val_loss: 0.4996 - val_accuracy: 0.8305\n",
      "Epoch 17/25\n",
      "48000/48000 [==============================] - 171s 4ms/sample - loss: 0.1674 - accuracy: 0.9318 - val_loss: 0.5296 - val_accuracy: 0.8305\n",
      "Epoch 18/25\n",
      "48000/48000 [==============================] - 171s 4ms/sample - loss: 0.1577 - accuracy: 0.9368 - val_loss: 0.5529 - val_accuracy: 0.8302\n",
      "Epoch 19/25\n",
      "48000/48000 [==============================] - 171s 4ms/sample - loss: 0.1464 - accuracy: 0.9429 - val_loss: 0.6017 - val_accuracy: 0.8277\n",
      "Epoch 20/25\n",
      "48000/48000 [==============================] - 172s 4ms/sample - loss: 0.1343 - accuracy: 0.9471 - val_loss: 0.5720 - val_accuracy: 0.8310\n",
      "Epoch 21/25\n",
      "48000/48000 [==============================] - 172s 4ms/sample - loss: 0.1242 - accuracy: 0.9523 - val_loss: 0.5896 - val_accuracy: 0.8312\n",
      "Epoch 22/25\n",
      "48000/48000 [==============================] - 171s 4ms/sample - loss: 0.1204 - accuracy: 0.9528 - val_loss: 0.6388 - val_accuracy: 0.8303\n",
      "Epoch 23/25\n",
      "48000/48000 [==============================] - 171s 4ms/sample - loss: 0.1128 - accuracy: 0.9569 - val_loss: 0.6587 - val_accuracy: 0.8273\n",
      "Epoch 24/25\n",
      "48000/48000 [==============================] - 171s 4ms/sample - loss: 0.1024 - accuracy: 0.9612 - val_loss: 0.7005 - val_accuracy: 0.8208\n",
      "Epoch 25/25\n",
      "48000/48000 [==============================] - 171s 4ms/sample - loss: 0.0990 - accuracy: 0.9622 - val_loss: 0.6824 - val_accuracy: 0.8282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f43181964d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 25, batch_size = 128, verbose = 1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 7s 1ms/sample - loss: 0.6977 - accuracy: 0.8298\n",
      "Loss = 0.6976528875430426\n",
      "Test Accuracy = 0.8298333\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(X_test, y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References \n",
    "\n",
    "This notebook presents the ResNet algorithm due to He et al. (2015). The implementation here also took significant inspiration and follows the structure given in the github repository of Francois Chollet: \n",
    "\n",
    "- Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun - [Deep Residual Learning for Image Recognition (2015)](https://arxiv.org/abs/1512.03385)\n",
    "- Francois Chollet's github repository: https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py\n"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "OEpi5",
   "launcher_item_id": "jK9EQ"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
