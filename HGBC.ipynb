{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('train.csv').drop(columns=['Id'])\n",
    "dfPred = pd.read_csv('testX.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_csv(model, name):\n",
    "    result = dfPred[['Id']].copy()\n",
    "    result['Label'] = model.predict(X_pred)\n",
    "    result.to_csv('result' + name + '.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_pca, X_test_pca, y_train, y_test = train_test_split(PCA(n_components = 30).fit_transform(StandardScaler().fit_transform(df.iloc[:,1:].values)), df.iloc[:,0], test_size=0.1, random_state = 42)\n",
    "pca = PCA(n_components = 30)\n",
    "ss = StandardScaler()\n",
    "X = pca.fit_transform(ss.fit_transform(df.iloc[:,1:].values))\n",
    "X_pred = pca.transform(ss.transform(dfPred.iloc[:,1:].values))\n",
    "clf = HistGradientBoostingClassifier(learning_rate=0.15, max_iter = 300, max_leaf_nodes=41, min_samples_leaf=22).fit(X, df.iloc[:,0])\n",
    "gen_csv(clf, 'HGBC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   47.4s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   50.5s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   53.8s\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 101 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 185 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 258 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 285 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 370 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 401 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 432 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 516 out of 540 | elapsed: 14.8min remaining:   41.4s\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed: 15.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([ 45.77184801,  43.94302421,  46.96711955,  44.368048  ,\n",
      "        50.35575376,  47.64178977,  54.43525963,  49.04586601,\n",
      "        52.79326401,  71.79640751,  77.06580477,  82.33377585,\n",
      "        93.67149305,  91.95012512,  83.25781169, 114.38330812,\n",
      "        97.76923809,  89.88902712,  32.28655958,  36.23689623,\n",
      "        37.41623807,  43.0420197 ,  44.96789742,  40.75395875,\n",
      "        46.8046196 ,  50.44933605,  57.56660328,  64.57518334,\n",
      "        67.48514438,  71.926052  ,  84.29469013,  84.52387009,\n",
      "        80.33780899, 102.4750165 , 106.56026101,  94.44364557,\n",
      "        32.18636346,  32.71936827,  33.91596079,  36.33167996,\n",
      "        40.76748033,  43.17967544,  45.34047918,  48.14519687,\n",
      "        40.67082896,  66.82466617,  70.59759874,  69.02140198,\n",
      "        90.56792326,  77.30229926,  84.88352451, 102.11829734,\n",
      "        93.06365185,  91.84145513,  32.86952834,  35.50100274,\n",
      "        33.1225029 ,  36.54788632,  45.77267079,  42.64430857,\n",
      "        42.6119935 ,  46.9889605 ,  49.09296241,  68.97586169,\n",
      "        70.81311049,  63.67184253,  90.47965674,  77.50657239,\n",
      "        85.36670909, 101.33524728, 111.18822317,  95.25217137,\n",
      "        32.24939694,  33.84836345,  32.31371446,  38.35658398,\n",
      "        41.70308299,  44.12859869,  49.31126556,  48.08661251,\n",
      "        45.77031794,  73.69557872,  76.31065669,  75.87777867,\n",
      "        88.55763183,  90.98832989,  83.2066288 , 101.84359651,\n",
      "        88.33054438, 104.98070407,  32.78179727,  38.44695449,\n",
      "        34.64342623,  41.95443611,  38.67939658,  45.53689585,\n",
      "        50.04919186,  51.93756413,  49.60553246,  72.25945697,\n",
      "        75.70129766,  75.58841982,  75.09493456,  71.07234325,\n",
      "        66.1912569 ,  68.35788865,  62.69400978,  44.03443627]),\n",
      " 'mean_score_time': array([2.36458645, 2.22308002, 2.40625286, 1.86526513, 2.34149704,\n",
      "       1.98090568, 1.96283102, 1.83840547, 2.100249  , 4.16135106,\n",
      "       4.40255685, 4.40818801, 4.05335255, 4.08760886, 4.03952718,\n",
      "       4.44937921, 3.79090896, 3.9228097 , 1.74185467, 2.20793991,\n",
      "       1.9587081 , 2.13244448, 2.20976572, 2.07526641, 2.07468467,\n",
      "       2.04733715, 2.39183564, 4.08978305, 4.19457235, 4.05531173,\n",
      "       4.22646704, 4.14596395, 3.92030873, 4.52625804, 4.37906032,\n",
      "       3.99839015, 2.15684323, 2.09191356, 2.39073262, 2.03893633,\n",
      "       2.21579289, 2.40350347, 2.044771  , 2.28544765, 1.92754617,\n",
      "       4.50531917, 4.5527288 , 4.72438679, 4.84171376, 3.86887007,\n",
      "       4.42943034, 4.2269516 , 3.93201761, 3.90141115, 2.21216135,\n",
      "       2.21725974, 2.30299225, 1.83805642, 2.32443371, 2.41343675,\n",
      "       2.1107667 , 2.17153578, 2.4250453 , 3.97135963, 4.35710721,\n",
      "       4.12362156, 4.4816493 , 4.2032856 , 4.29869523, 4.13107157,\n",
      "       4.45966434, 4.10549297, 2.15915389, 2.3137568 , 2.06378307,\n",
      "       2.12608094, 2.23208594, 2.22996416, 2.318084  , 2.02492671,\n",
      "       2.00312529, 4.66702189, 4.59721532, 4.39097443, 4.71453199,\n",
      "       4.53171768, 4.11671333, 4.52421408, 3.50249791, 4.54446173,\n",
      "       2.09838495, 2.28375006, 2.26914949, 2.14529948, 2.10927348,\n",
      "       2.49778786, 2.17921019, 2.10249538, 2.53085508, 4.63091784,\n",
      "       4.07823005, 3.59289446, 2.59666042, 1.97147551, 1.69315152,\n",
      "       0.5921113 , 0.55541792, 0.47649422]),\n",
      " 'mean_test_score': array([0.87298333, 0.87321667, 0.87335   , 0.87625   , 0.87686667,\n",
      "       0.87615   , 0.87901667, 0.87873333, 0.87896667, 0.8807    ,\n",
      "       0.87998333, 0.88116667, 0.88335   , 0.8832    , 0.88331667,\n",
      "       0.88443333, 0.88436667, 0.88451667, 0.8537    , 0.85311667,\n",
      "       0.84908333, 0.83775   , 0.85743333, 0.83581667, 0.83733333,\n",
      "       0.83756667, 0.8722    , 0.82611667, 0.82851667, 0.81246667,\n",
      "       0.79713333, 0.83213333, 0.80658333, 0.7897    , 0.80058333,\n",
      "       0.84118333, 0.82048333, 0.81936667, 0.82015   , 0.80748333,\n",
      "       0.81231667, 0.81051667, 0.80336667, 0.80028333, 0.80436667,\n",
      "       0.7768    , 0.7864    , 0.7808    , 0.77323333, 0.77256667,\n",
      "       0.75781667, 0.74245   , 0.76783333, 0.73156667, 0.79783333,\n",
      "       0.79623333, 0.7868    , 0.78048333, 0.78466667, 0.78466667,\n",
      "       0.78076667, 0.78073333, 0.77516667, 0.75081667, 0.75605   ,\n",
      "       0.73993333, 0.74433333, 0.74086667, 0.73813333, 0.72931667,\n",
      "       0.70856667, 0.73766667, 0.77026667, 0.7746    , 0.77168333,\n",
      "       0.76938333, 0.7562    , 0.75218333, 0.75976667, 0.74273333,\n",
      "       0.75356667, 0.7091    , 0.73226667, 0.69605   , 0.60948333,\n",
      "       0.57896667, 0.3957    , 0.46645   , 0.29551667, 0.28521667,\n",
      "       0.75246667, 0.75773333, 0.75701667, 0.74416667, 0.75008333,\n",
      "       0.73571667, 0.752     , 0.75468333, 0.73876667, 0.61473333,\n",
      "       0.60338333, 0.50025   , 0.3026    , 0.30678333, 0.20001667,\n",
      "       0.20005   , 0.24035   , 0.19983333]),\n",
      " 'param_learning_rate': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.3, 0.3, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
      "                   0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
      "                   0.9, 0.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   1, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_max_iter': masked_array(data=[100, 100, 100, 100, 100, 100, 100, 100, 100, 200, 200,\n",
      "                   200, 200, 200, 200, 200, 200, 200, 100, 100, 100, 100,\n",
      "                   100, 100, 100, 100, 100, 200, 200, 200, 200, 200, 200,\n",
      "                   200, 200, 200, 100, 100, 100, 100, 100, 100, 100, 100,\n",
      "                   100, 200, 200, 200, 200, 200, 200, 200, 200, 200, 100,\n",
      "                   100, 100, 100, 100, 100, 100, 100, 100, 200, 200, 200,\n",
      "                   200, 200, 200, 200, 200, 200, 100, 100, 100, 100, 100,\n",
      "                   100, 100, 100, 100, 200, 200, 200, 200, 200, 200, 200,\n",
      "                   200, 200, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
      "                   200, 200, 200, 200, 200, 200, 200, 200, 200],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_max_leaf_nodes': masked_array(data=[25, 25, 25, 31, 31, 31, 37, 37, 37, 25, 25, 25, 31, 31,\n",
      "                   31, 37, 37, 37, 25, 25, 25, 31, 31, 31, 37, 37, 37, 25,\n",
      "                   25, 25, 31, 31, 31, 37, 37, 37, 25, 25, 25, 31, 31, 31,\n",
      "                   37, 37, 37, 25, 25, 25, 31, 31, 31, 37, 37, 37, 25, 25,\n",
      "                   25, 31, 31, 31, 37, 37, 37, 25, 25, 25, 31, 31, 31, 37,\n",
      "                   37, 37, 25, 25, 25, 31, 31, 31, 37, 37, 37, 25, 25, 25,\n",
      "                   31, 31, 31, 37, 37, 37, 25, 25, 25, 31, 31, 31, 37, 37,\n",
      "                   37, 25, 25, 25, 31, 31, 31, 37, 37, 37],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_min_samples_leaf': masked_array(data=[16, 20, 24, 16, 20, 24, 16, 20, 24, 16, 20, 24, 16, 20,\n",
      "                   24, 16, 20, 24, 16, 20, 24, 16, 20, 24, 16, 20, 24, 16,\n",
      "                   20, 24, 16, 20, 24, 16, 20, 24, 16, 20, 24, 16, 20, 24,\n",
      "                   16, 20, 24, 16, 20, 24, 16, 20, 24, 16, 20, 24, 16, 20,\n",
      "                   24, 16, 20, 24, 16, 20, 24, 16, 20, 24, 16, 20, 24, 16,\n",
      "                   20, 24, 16, 20, 24, 16, 20, 24, 16, 20, 24, 16, 20, 24,\n",
      "                   16, 20, 24, 16, 20, 24, 16, 20, 24, 16, 20, 24, 16, 20,\n",
      "                   24, 16, 20, 24, 16, 20, 24, 16, 20, 24],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'params': [{'learning_rate': 0.1,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.3,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.3,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.3,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.3,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.3,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.3,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.3,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.3,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.3,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.3,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.3,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.3,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.3,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.3,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.3,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.3,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.3,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.3,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.5,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.5,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.5,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.5,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.5,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.5,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.5,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.5,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.5,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.5,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.5,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.5,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.5,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.5,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.5,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.5,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.5,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.5,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.7,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.7,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.7,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.7,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.7,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.7,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.7,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.7,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.7,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.7,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.7,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.7,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.7,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.7,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.7,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.7,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.7,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.7,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.9,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.9,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.9,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.9,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.9,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.9,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.9,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.9,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.9,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.9,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.9,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.9,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.9,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.9,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.9,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.9,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 0.9,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 0.9,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 1,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 1,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 1,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 1,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 1,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 1,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 1,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 1,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 1,\n",
      "             'max_iter': 100,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 25,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 31,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 16},\n",
      "            {'learning_rate': 1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 20},\n",
      "            {'learning_rate': 1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24}],\n",
      " 'rank_test_score': array([ 18,  17,  16,  14,  13,  15,  10,  12,  11,   8,   9,   7,   4,\n",
      "         6,   5,   2,   3,   1,  21,  22,  23,  25,  20,  28,  27,  26,\n",
      "        19,  31,  30,  35,  45,  29,  39,  47,  42,  24,  32,  34,  33,\n",
      "        38,  36,  37,  41,  43,  40,  56,  49,  52,  59,  60,  66,  81,\n",
      "        64,  89,  44,  46,  48,  55,  50,  50,  53,  54,  57,  76,  70,\n",
      "        83,  78,  82,  85,  90,  92,  86,  62,  58,  61,  63,  69,  74,\n",
      "        65,  80,  72,  91,  88,  93,  95,  97, 100,  99, 103, 104,  73,\n",
      "        67,  68,  79,  77,  87,  75,  71,  84,  94,  96,  98, 102, 101,\n",
      "       107, 106, 105, 108], dtype=int32),\n",
      " 'split0_test_score': array([0.86958333, 0.87141667, 0.86983333, 0.87483333, 0.87566667,\n",
      "       0.87183333, 0.87791667, 0.87691667, 0.87625   , 0.87816667,\n",
      "       0.87975   , 0.88075   , 0.883     , 0.882     , 0.88033333,\n",
      "       0.88541667, 0.88283333, 0.88408333, 0.8485    , 0.84375   ,\n",
      "       0.84258333, 0.8325    , 0.87891667, 0.83766667, 0.8245    ,\n",
      "       0.87825   , 0.87891667, 0.83066667, 0.80958333, 0.80558333,\n",
      "       0.80741667, 0.88466667, 0.80266667, 0.77625   , 0.88533333,\n",
      "       0.886     , 0.82516667, 0.82266667, 0.82416667, 0.81333333,\n",
      "       0.81033333, 0.81941667, 0.78091667, 0.80633333, 0.81491667,\n",
      "       0.77741667, 0.796     , 0.781     , 0.77841667, 0.76975   ,\n",
      "       0.78075   , 0.74291667, 0.76133333, 0.70941667, 0.79541667,\n",
      "       0.79625   , 0.78875   , 0.7585    , 0.79066667, 0.77791667,\n",
      "       0.78791667, 0.77958333, 0.79041667, 0.74858333, 0.75791667,\n",
      "       0.7625    , 0.73775   , 0.73291667, 0.73441667, 0.75058333,\n",
      "       0.72258333, 0.74041667, 0.76183333, 0.765     , 0.77233333,\n",
      "       0.76108333, 0.74016667, 0.76633333, 0.74183333, 0.73708333,\n",
      "       0.767     , 0.62883333, 0.71383333, 0.74408333, 0.19958333,\n",
      "       0.659     , 0.74058333, 0.19991667, 0.6785    , 0.20116667,\n",
      "       0.77308333, 0.752     , 0.76233333, 0.759     , 0.757     ,\n",
      "       0.72933333, 0.75775   , 0.76075   , 0.76191667, 0.73158333,\n",
      "       0.74683333, 0.71458333, 0.19958333, 0.19991667, 0.20116667,\n",
      "       0.19958333, 0.40183333, 0.19991667]),\n",
      " 'split1_test_score': array([0.87808333, 0.87616667, 0.87608333, 0.879     , 0.88041667,\n",
      "       0.88008333, 0.88275   , 0.87933333, 0.8825    , 0.8845    ,\n",
      "       0.8835    , 0.88333333, 0.88633333, 0.8855    , 0.88466667,\n",
      "       0.88666667, 0.8865    , 0.88866667, 0.8545    , 0.84258333,\n",
      "       0.8555    , 0.84275   , 0.835     , 0.83716667, 0.844     ,\n",
      "       0.83891667, 0.883     , 0.82625   , 0.82083333, 0.8225    ,\n",
      "       0.78641667, 0.78883333, 0.81508333, 0.80766667, 0.78366667,\n",
      "       0.88758333, 0.81883333, 0.80991667, 0.82108333, 0.81025   ,\n",
      "       0.80825   , 0.80408333, 0.80441667, 0.80291667, 0.80308333,\n",
      "       0.77808333, 0.789     , 0.77966667, 0.766     , 0.78258333,\n",
      "       0.77941667, 0.76191667, 0.77791667, 0.70366667, 0.79958333,\n",
      "       0.78883333, 0.77583333, 0.77358333, 0.7855    , 0.78825   ,\n",
      "       0.77616667, 0.78733333, 0.78158333, 0.75875   , 0.76166667,\n",
      "       0.708     , 0.74375   , 0.73683333, 0.72341667, 0.71316667,\n",
      "       0.741     , 0.74416667, 0.766     , 0.77558333, 0.77775   ,\n",
      "       0.77033333, 0.7635    , 0.761     , 0.76241667, 0.73975   ,\n",
      "       0.76391667, 0.71083333, 0.72433333, 0.73783333, 0.707     ,\n",
      "       0.71066667, 0.19991667, 0.61283333, 0.19991667, 0.19975   ,\n",
      "       0.76116667, 0.76933333, 0.74025   , 0.72775   , 0.73858333,\n",
      "       0.72608333, 0.73358333, 0.74366667, 0.69375   , 0.73925   ,\n",
      "       0.71608333, 0.20116667, 0.19975   , 0.19991667, 0.19958333,\n",
      "       0.20116667, 0.19958333, 0.19975   ]),\n",
      " 'split2_test_score': array([0.87383333, 0.87566667, 0.87533333, 0.88025   , 0.87916667,\n",
      "       0.87866667, 0.88333333, 0.88166667, 0.88266667, 0.88283333,\n",
      "       0.87991667, 0.8825    , 0.88575   , 0.88691667, 0.88875   ,\n",
      "       0.88766667, 0.88816667, 0.88616667, 0.85583333, 0.85783333,\n",
      "       0.87125   , 0.85183333, 0.88316667, 0.8435    , 0.83541667,\n",
      "       0.81766667, 0.87916667, 0.82558333, 0.82558333, 0.81108333,\n",
      "       0.80283333, 0.88841667, 0.808     , 0.79916667, 0.77883333,\n",
      "       0.78958333, 0.82783333, 0.82666667, 0.82641667, 0.81266667,\n",
      "       0.82383333, 0.806     , 0.8255    , 0.80583333, 0.81116667,\n",
      "       0.76008333, 0.79033333, 0.77791667, 0.78866667, 0.78591667,\n",
      "       0.77416667, 0.72      , 0.76875   , 0.755     , 0.80733333,\n",
      "       0.80225   , 0.791     , 0.79591667, 0.775     , 0.77775   ,\n",
      "       0.78416667, 0.78891667, 0.75866667, 0.74325   , 0.76025   ,\n",
      "       0.72075   , 0.77166667, 0.74      , 0.72633333, 0.73641667,\n",
      "       0.73983333, 0.74241667, 0.77425   , 0.77766667, 0.77258333,\n",
      "       0.77483333, 0.76383333, 0.74      , 0.76083333, 0.74741667,\n",
      "       0.75508333, 0.75325   , 0.75508333, 0.68533333, 0.71691667,\n",
      "       0.63616667, 0.19983333, 0.67975   , 0.19966667, 0.19966667,\n",
      "       0.7315    , 0.74358333, 0.76483333, 0.74533333, 0.7505    ,\n",
      "       0.73675   , 0.76241667, 0.76525   , 0.74733333, 0.6915    ,\n",
      "       0.19983333, 0.68358333, 0.71283333, 0.7345    , 0.19983333,\n",
      "       0.19983333, 0.19958333, 0.19966667]),\n",
      " 'split3_test_score': array([0.87291667, 0.87125   , 0.87333333, 0.87308333, 0.87333333,\n",
      "       0.87358333, 0.87458333, 0.87741667, 0.87616667, 0.8795    ,\n",
      "       0.87816667, 0.87958333, 0.88125   , 0.87958333, 0.88116667,\n",
      "       0.87975   , 0.8815    , 0.88158333, 0.84308333, 0.84891667,\n",
      "       0.83783333, 0.83191667, 0.83766667, 0.83308333, 0.83575   ,\n",
      "       0.82641667, 0.876     , 0.823     , 0.81075   , 0.82233333,\n",
      "       0.78416667, 0.80441667, 0.80475   , 0.7735    , 0.78508333,\n",
      "       0.88291667, 0.81758333, 0.82      , 0.81908333, 0.79883333,\n",
      "       0.80916667, 0.81816667, 0.799     , 0.79825   , 0.80125   ,\n",
      "       0.78191667, 0.77916667, 0.787     , 0.76616667, 0.75841667,\n",
      "       0.68358333, 0.7555    , 0.74983333, 0.74791667, 0.79358333,\n",
      "       0.803     , 0.78966667, 0.78883333, 0.79216667, 0.792     ,\n",
      "       0.77008333, 0.773     , 0.78508333, 0.76766667, 0.77908333,\n",
      "       0.74433333, 0.76325   , 0.75241667, 0.74258333, 0.73075   ,\n",
      "       0.62966667, 0.71458333, 0.77      , 0.78033333, 0.772     ,\n",
      "       0.77241667, 0.75116667, 0.75433333, 0.76908333, 0.73608333,\n",
      "       0.74208333, 0.71983333, 0.73525   , 0.72858333, 0.73116667,\n",
      "       0.68925   , 0.6385    , 0.19991667, 0.19975   , 0.20108333,\n",
      "       0.75116667, 0.77341667, 0.76041667, 0.747     , 0.74858333,\n",
      "       0.74441667, 0.76216667, 0.75391667, 0.739     , 0.19966667,\n",
      "       0.65775   , 0.20108333, 0.19975   , 0.19991667, 0.19991667,\n",
      "       0.19991667, 0.19966667, 0.19991667]),\n",
      " 'split4_test_score': array([0.8705    , 0.87158333, 0.87216667, 0.87408333, 0.87575   ,\n",
      "       0.87658333, 0.8765    , 0.87833333, 0.87725   , 0.8785    ,\n",
      "       0.87858333, 0.87966667, 0.88041667, 0.882     , 0.88166667,\n",
      "       0.88266667, 0.88283333, 0.88208333, 0.86658333, 0.8725    ,\n",
      "       0.83825   , 0.82975   , 0.85241667, 0.82766667, 0.847     ,\n",
      "       0.82658333, 0.84391667, 0.82508333, 0.87583333, 0.80083333,\n",
      "       0.80483333, 0.79433333, 0.80241667, 0.79191667, 0.77      ,\n",
      "       0.75983333, 0.813     , 0.81758333, 0.81      , 0.80233333,\n",
      "       0.81      , 0.80491667, 0.807     , 0.78808333, 0.79141667,\n",
      "       0.7865    , 0.7775    , 0.77841667, 0.76691667, 0.76616667,\n",
      "       0.77116667, 0.73191667, 0.78133333, 0.74183333, 0.79325   ,\n",
      "       0.79083333, 0.78875   , 0.78558333, 0.78      , 0.78741667,\n",
      "       0.7855    , 0.77483333, 0.76008333, 0.73583333, 0.72133333,\n",
      "       0.76408333, 0.70525   , 0.74216667, 0.76391667, 0.71566667,\n",
      "       0.70975   , 0.74675   , 0.77925   , 0.77441667, 0.76375   ,\n",
      "       0.76825   , 0.76233333, 0.73925   , 0.76466667, 0.75333333,\n",
      "       0.73975   , 0.73275   , 0.73283333, 0.58441667, 0.69275   ,\n",
      "       0.19975   , 0.19966667, 0.63983333, 0.19975   , 0.62441667,\n",
      "       0.74541667, 0.75033333, 0.75725   , 0.74175   , 0.75575   ,\n",
      "       0.742     , 0.74408333, 0.74983333, 0.75183333, 0.71166667,\n",
      "       0.69641667, 0.70083333, 0.20108333, 0.19966667, 0.19958333,\n",
      "       0.19975   , 0.20108333, 0.19991667]),\n",
      " 'std_fit_time': array([ 1.35697272,  3.87845383,  0.754865  ,  1.52781159,  6.0113985 ,\n",
      "        3.98752984,  7.00734448,  1.53415598,  4.72681655,  6.46392314,\n",
      "        6.84009945,  7.69761083, 11.23718037, 11.89296836,  8.75609272,\n",
      "        3.61516807, 11.83254838,  3.18484105,  1.3457534 ,  3.83044181,\n",
      "        3.85556346,  4.5420601 ,  6.00979907,  4.00178842,  4.25538252,\n",
      "        5.01524457,  2.07748961,  5.19701587,  6.3144208 ,  6.55800949,\n",
      "       10.30311558, 12.4395871 ,  7.53792744,  8.97893743,  7.60703417,\n",
      "        9.6770368 ,  3.09427421,  3.8727691 ,  3.18074217,  2.62429601,\n",
      "        4.36083826,  4.18158961,  5.78711423,  4.71811323,  1.95767066,\n",
      "        4.86382378,  7.83972504,  8.89716709,  5.45390514,  4.36995092,\n",
      "        9.72474058,  6.95587058, 11.5819068 , 10.66801466,  1.6852171 ,\n",
      "        3.42805171,  3.51294553,  1.98649856,  2.02332769,  4.0835066 ,\n",
      "        3.55322319,  5.44452052,  6.07389702,  4.4249869 ,  6.02379107,\n",
      "        1.43981223,  7.86344174,  5.89636805,  6.62429424,  7.5869937 ,\n",
      "        8.45202047,  9.54158368,  1.75529213,  3.19215698,  1.39609774,\n",
      "        3.81363434,  4.40735352,  2.15539058,  7.30777128,  7.11537923,\n",
      "        6.1588357 ,  8.53459803,  4.59496922,  4.94853903,  9.56408978,\n",
      "       11.56857181, 12.73193234, 11.67676378,  8.5499264 , 12.49731569,\n",
      "        1.87002423,  1.78199201,  2.36854508,  3.85485566,  3.28977793,\n",
      "        4.25660114,  6.47942128,  5.84322362,  7.08944489,  6.82089256,\n",
      "        5.8599403 ,  6.9671103 ,  4.54308712,  6.92957807,  4.82674618,\n",
      "        2.2294807 ,  2.3872348 ,  4.9949041 ]),\n",
      " 'std_score_time': array([0.23330183, 0.20006732, 0.09971032, 0.06997679, 0.28470228,\n",
      "       0.26039544, 0.23677179, 0.10072953, 0.16399737, 0.29307274,\n",
      "       0.62097525, 0.52289285, 0.36233195, 0.33103404, 0.47545075,\n",
      "       0.39989472, 0.57262024, 0.34857709, 0.27961055, 0.18484485,\n",
      "       0.28777451, 0.26327431, 0.26358384, 0.20754436, 0.23982023,\n",
      "       0.13212321, 0.05140246, 0.29691281, 0.31451185, 0.2655328 ,\n",
      "       0.39779708, 0.57787628, 0.39128115, 0.23383724, 0.38974036,\n",
      "       0.28683049, 0.27067689, 0.23176067, 0.32330845, 0.08088452,\n",
      "       0.21317147, 0.12055575, 0.25462637, 0.16104181, 0.16528118,\n",
      "       0.76008927, 0.40294816, 0.78795483, 0.57658011, 0.09469644,\n",
      "       0.59276604, 0.37099841, 0.36036216, 0.39517629, 0.13103548,\n",
      "       0.31231784, 0.26806766, 0.05170642, 0.21873596, 0.30811361,\n",
      "       0.31888587, 0.17307392, 0.21627352, 0.29930871, 0.5454794 ,\n",
      "       0.18603602, 0.36892395, 0.33039282, 0.55792035, 0.65988314,\n",
      "       0.55386395, 0.2644346 , 0.14533363, 0.1528973 , 0.20512671,\n",
      "       0.22171285, 0.36657586, 0.21830897, 0.34333895, 0.1359054 ,\n",
      "       0.19475681, 0.63953348, 0.55287396, 0.67859788, 0.41186187,\n",
      "       0.17110283, 0.89675753, 0.58296693, 0.33634751, 0.73536281,\n",
      "       0.10274277, 0.53786015, 0.25660652, 0.21573852, 0.13660688,\n",
      "       0.41672955, 0.27561879, 0.29996102, 0.4105498 , 0.53820455,\n",
      "       0.19193873, 0.71377307, 0.25953429, 0.92836708, 0.50782205,\n",
      "       0.10837982, 0.06619601, 0.03657176]),\n",
      " 'std_test_score': array([2.98207609e-03, 2.21271578e-03, 2.24375677e-03, 2.83872037e-03,\n",
      "       2.57153218e-03, 3.07291031e-03, 3.45743964e-03, 1.68275568e-03,\n",
      "       2.97797470e-03, 2.51749435e-03, 1.88075044e-03, 1.51015084e-03,\n",
      "       2.35784742e-03, 2.64816498e-03, 3.08508959e-03, 2.87971835e-03,\n",
      "       2.52630604e-03, 2.63280585e-03, 7.88574664e-03, 1.10840977e-02,\n",
      "       1.27961583e-02, 8.35380818e-03, 2.02132657e-02, 5.25684739e-03,\n",
      "       7.85829357e-03, 2.14379207e-02, 1.43155510e-02, 2.52135325e-03,\n",
      "       2.44156940e-02, 8.74811091e-03, 9.80314575e-03, 4.47202601e-02,\n",
      "       4.69722140e-03, 1.31200229e-02, 4.27021987e-02, 5.51063467e-02,\n",
      "       5.34955865e-03, 5.60471032e-03, 5.66455843e-03, 5.83247613e-03,\n",
      "       5.80335152e-03, 6.79530066e-03, 1.43335853e-02, 6.74260912e-03,\n",
      "       8.20494431e-03, 8.96375417e-03, 7.01316223e-03, 3.27897342e-03,\n",
      "       9.02456524e-03, 1.02729959e-02, 3.72790304e-02, 1.52605701e-02,\n",
      "       1.14106432e-02, 2.09326566e-02, 5.25779844e-03, 5.76035300e-03,\n",
      "       5.54491759e-03, 1.31514047e-02, 6.45238974e-03, 5.78935805e-03,\n",
      "       6.63898419e-03, 6.42594567e-03, 1.32047971e-02, 1.12570225e-02,\n",
      "       1.89127088e-02, 2.23587790e-02, 2.31349903e-02, 6.56222354e-03,\n",
      "       1.45204454e-02, 1.37976850e-02, 4.11159404e-02, 1.17279344e-02,\n",
      "       6.09858818e-03, 5.20453862e-03, 4.49610943e-03, 4.69000118e-03,\n",
      "       9.29061653e-03, 1.09387690e-02, 9.38695904e-03, 6.62327546e-03,\n",
      "       1.10692768e-02, 4.25898853e-02, 1.36568461e-02, 5.94782547e-02,\n",
      "       2.05333681e-01, 1.91305911e-01, 2.42082749e-01, 2.18662656e-01,\n",
      "       1.91491684e-01, 1.69601187e-01, 1.40835404e-02, 1.15618386e-02,\n",
      "       8.74188513e-03, 1.00475260e-02, 6.55171733e-03, 7.06804232e-03,\n",
      "       1.13734584e-02, 7.66728258e-03, 2.36922045e-02, 2.08195991e-01,\n",
      "       2.03834605e-01, 2.44432034e-01, 2.05117381e-01, 2.13858355e-01,\n",
      "       5.90197707e-04, 5.69112369e-04, 8.07436857e-02, 1.05409255e-04])}\n",
      "{'learning_rate': 0.1,\n",
      " 'max_iter': 200,\n",
      " 'max_leaf_nodes': 37,\n",
      " 'min_samples_leaf': 24}\n"
     ]
    }
   ],
   "source": [
    "X = PCA(n_components = 30).fit_transform(StandardScaler().fit_transform(df.iloc[:,1:]))\n",
    "parameters = {'learning_rate': [0.1, 0.3, 0.5, 0.7, 0.9, 1], \n",
    "              'max_iter': [100, 200], \n",
    "              'max_leaf_nodes': [25, 31, 37],\n",
    "              'min_samples_leaf': [16, 20, 24]}\n",
    "modelHGBC = GridSearchCV(HistGradientBoostingClassifier(random_state=42), parameters, n_jobs = -1, verbose=10).fit(X, df.iloc[:,0])\n",
    "pprint(modelHGBC.cv_results_)\n",
    "pprint(modelHGBC.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 256 candidates, totalling 1280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 101 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 185 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 258 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done 285 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed: 17.5min\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=-1)]: Done 370 tasks      | elapsed: 19.7min\n",
      "[Parallel(n_jobs=-1)]: Done 401 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=-1)]: Done 432 tasks      | elapsed: 22.5min\n",
      "[Parallel(n_jobs=-1)]: Done 465 tasks      | elapsed: 24.1min\n",
      "[Parallel(n_jobs=-1)]: Done 498 tasks      | elapsed: 26.2min\n",
      "[Parallel(n_jobs=-1)]: Done 533 tasks      | elapsed: 28.2min\n",
      "[Parallel(n_jobs=-1)]: Done 568 tasks      | elapsed: 30.5min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed: 32.9min\n",
      "[Parallel(n_jobs=-1)]: Done 642 tasks      | elapsed: 34.8min\n",
      "[Parallel(n_jobs=-1)]: Done 681 tasks      | elapsed: 36.1min\n",
      "[Parallel(n_jobs=-1)]: Done 720 tasks      | elapsed: 37.7min\n",
      "[Parallel(n_jobs=-1)]: Done 761 tasks      | elapsed: 39.6min\n",
      "[Parallel(n_jobs=-1)]: Done 802 tasks      | elapsed: 41.7min\n",
      "[Parallel(n_jobs=-1)]: Done 845 tasks      | elapsed: 44.4min\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed: 47.2min\n",
      "[Parallel(n_jobs=-1)]: Done 933 tasks      | elapsed: 50.2min\n",
      "[Parallel(n_jobs=-1)]: Done 978 tasks      | elapsed: 52.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1025 tasks      | elapsed: 53.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1072 tasks      | elapsed: 55.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1121 tasks      | elapsed: 58.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1170 tasks      | elapsed: 61.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1280 out of 1280 | elapsed: 66.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([ 88.42371321,  83.17815938,  79.06949925,  80.62228627,\n",
      "        85.27868867,  80.63835669,  88.72199039,  88.97455063,\n",
      "        76.39080067,  81.63706031,  82.30457563,  79.06292143,\n",
      "       100.52272811, 104.07968693, 105.79383111, 104.7550086 ,\n",
      "        90.72324357,  92.86198325,  98.91677332,  97.68559608,\n",
      "       120.99022756, 121.99258604, 121.83954782, 119.78580861,\n",
      "       100.18167162,  99.30153103,  98.76290383, 115.20617757,\n",
      "       128.75398245, 130.45018239, 133.57706738, 131.42577438,\n",
      "       112.25755386, 115.71995659, 110.46482573, 127.53650517,\n",
      "       140.27090182, 144.57370868, 126.70887723, 146.95152545,\n",
      "       138.02954845, 134.66757693, 127.26815596, 131.99775248,\n",
      "       141.49178443, 139.44870353, 137.60471087, 145.07841969,\n",
      "       153.48798943, 156.79470778, 161.00144711, 147.85331655,\n",
      "       158.21805553, 141.49976497, 153.88401957, 157.67287216,\n",
      "       178.44170876, 167.31828017, 169.01117444, 158.7386476 ,\n",
      "       153.36262512, 161.50889502, 172.23867745, 177.64094596,\n",
      "        78.74574027,  73.64363842,  84.45856371,  79.35767069,\n",
      "        81.59498539,  77.68090029,  83.46177459,  78.99936013,\n",
      "        97.46895661,  80.1012053 ,  91.80204887,  76.44245925,\n",
      "        93.88710909,  90.97900138,  91.56027436,  98.04289722,\n",
      "        94.66220436, 110.1897265 , 101.95121131, 102.68239856,\n",
      "       110.82744241, 102.1552846 , 108.43449125, 110.59886351,\n",
      "       113.41363249, 112.75343046, 105.19600091, 122.55188756,\n",
      "       105.02481041, 116.57261443, 131.9776906 , 107.86748776,\n",
      "       123.56472893, 122.1494792 , 135.310074  , 130.10497231,\n",
      "       140.31778827, 125.90847363, 118.26167574, 143.8320365 ,\n",
      "       132.72168312, 141.86919456, 135.39606833, 143.35333862,\n",
      "       150.30647264, 133.93014007, 135.5257071 , 136.9038672 ,\n",
      "       158.69744897, 146.81738882, 140.36334362, 151.35629544,\n",
      "       155.05072026, 150.6885375 , 162.87964921, 153.36358395,\n",
      "       148.5926919 , 172.44482403, 153.80749311, 154.96528645,\n",
      "       168.68664298, 172.45144081, 154.20488439, 184.39280014,\n",
      "        72.64609423,  72.16137619,  78.66048808,  71.90475073,\n",
      "        74.54157143,  79.048559  ,  83.18349319,  72.8059896 ,\n",
      "        78.25372891,  83.0067791 ,  84.13887415,  86.42415223,\n",
      "        85.12664146,  84.89318428,  83.56705337,  88.65303435,\n",
      "        94.65204291,  98.75051742, 101.20131998,  98.24470139,\n",
      "       110.51458206,  96.79600482, 103.08669276, 112.77688112,\n",
      "        98.81032548, 104.4029891 , 116.31338425, 113.49229131,\n",
      "       117.90933595, 111.41590261, 119.42501783, 120.15048862,\n",
      "       118.97189665, 119.91770935, 121.94015479, 133.84550347,\n",
      "       126.62157593, 132.76577125, 123.13674774, 134.67813239,\n",
      "       140.95322895, 136.97542419, 132.3605845 , 130.54053979,\n",
      "       141.91270247, 139.76269193, 144.1815485 , 146.35840416,\n",
      "       150.24293046, 158.92804632, 140.31805806, 139.46450977,\n",
      "       149.47502642, 156.20866733, 154.8804307 , 151.05330405,\n",
      "       165.39724517, 158.23981662, 172.83392391, 156.73988357,\n",
      "       163.06567645, 152.65853419, 159.27841229, 166.60819468,\n",
      "        75.46881514,  68.337783  ,  69.36158128,  77.6912672 ,\n",
      "        83.61614065,  82.75708394,  75.00740275,  70.49780822,\n",
      "        76.81080728,  81.92157469,  81.32444873,  81.85554571,\n",
      "        80.32173553,  77.93756557,  86.71530943,  91.30300479,\n",
      "        92.61291676,  94.97274652,  96.24966259, 100.46936488,\n",
      "        93.36022062, 101.48053274, 102.81551523, 102.70628176,\n",
      "       107.57988496, 100.79300265, 116.12559471, 103.97401538,\n",
      "       100.48602901, 107.73046837, 110.98453903, 105.31636982,\n",
      "       122.23215795, 124.07961664, 122.74253716, 115.42434959,\n",
      "       127.16197023, 127.97272635, 118.35337615, 127.15611057,\n",
      "       131.49406323, 130.54371133, 128.79698563, 137.57575693,\n",
      "       135.52653651, 131.54652634, 142.00177007, 139.686516  ,\n",
      "       140.4974731 , 141.7335011 , 142.42410188, 141.58893552,\n",
      "       146.97784696, 149.61231856, 158.26287827, 148.49446163,\n",
      "       163.00271144, 154.26941853, 145.56113625, 135.1943707 ,\n",
      "       134.04670701, 122.6866034 , 104.7231936 ,  87.16426921]),\n",
      " 'mean_score_time': array([3.41465077, 3.29615798, 3.03882384, 3.18551412, 2.99660864,\n",
      "       3.11782365, 3.13980937, 3.18394198, 2.85536404, 3.07193804,\n",
      "       2.92024693, 2.84695826, 3.33270097, 3.50709372, 3.50141931,\n",
      "       3.44178352, 3.85213847, 3.44057469, 4.1042902 , 4.09924932,\n",
      "       4.56699381, 4.55360761, 4.42338324, 4.88129039, 3.84740448,\n",
      "       3.84564395, 3.78586054, 4.61374722, 4.8002862 , 4.78676729,\n",
      "       5.07130456, 4.59915209, 4.55348582, 5.11752629, 4.67922902,\n",
      "       5.36217203, 5.3723392 , 5.8207705 , 5.20270519, 6.39702454,\n",
      "       5.90380821, 5.31873317, 5.2388938 , 5.50816813, 5.47597837,\n",
      "       5.33279762, 5.25979567, 5.34809928, 6.63247967, 6.91297903,\n",
      "       6.83171773, 5.69829931, 6.41099219, 6.03040571, 6.22570496,\n",
      "       6.74111843, 6.92732406, 5.85454316, 6.87116079, 6.59164081,\n",
      "       5.86941857, 5.90604572, 6.44498081, 7.09722195, 3.30158167,\n",
      "       3.27744379, 3.54529319, 3.39940434, 3.31835942, 2.9739387 ,\n",
      "       3.30059409, 3.25344858, 3.67896419, 2.9422195 , 3.49337044,\n",
      "       3.19306407, 3.43353281, 3.30217543, 3.15269012, 3.58550429,\n",
      "       4.08626094, 4.64624338, 4.53639798, 4.38772001, 4.6177669 ,\n",
      "       4.24361806, 4.22652292, 4.50421958, 4.60448112, 4.60386415,\n",
      "       3.93467169, 4.46105185, 4.08563614, 4.13440156, 4.57876334,\n",
      "       4.1141963 , 5.7524209 , 5.37199688, 5.77167859, 4.55060358,\n",
      "       5.15283084, 5.18963976, 4.84199815, 6.11723938, 5.28141823,\n",
      "       5.61945896, 5.44095855, 5.47783842, 5.03681397, 5.0236444 ,\n",
      "       5.42792792, 5.27256002, 7.03454914, 6.9934154 , 6.12551169,\n",
      "       6.37514019, 6.50603371, 6.70939813, 6.53663988, 6.77274981,\n",
      "       5.98054442, 6.83646026, 5.73713875, 6.7456636 , 6.56315174,\n",
      "       6.88648429, 6.10068488, 7.12604342, 3.25407786, 3.06982408,\n",
      "       3.35422683, 3.53470802, 3.03721261, 3.45335774, 3.57279153,\n",
      "       2.94687629, 3.22934308, 3.47415524, 3.35119696, 3.48538222,\n",
      "       3.57704701, 3.51188159, 3.350033  , 3.20037947, 3.92042947,\n",
      "       4.58430691, 4.97467628, 4.51786957, 4.95990705, 4.36627007,\n",
      "       4.47539043, 4.6464839 , 4.06764255, 4.17234354, 4.77058473,\n",
      "       4.82269235, 4.69558606, 4.00849757, 4.41633544, 4.9924684 ,\n",
      "       5.55477467, 5.61907039, 5.56301908, 6.06612511, 5.67424669,\n",
      "       5.87318816, 5.04531412, 5.0897913 , 6.28809681, 5.90830932,\n",
      "       5.182407  , 5.473634  , 5.94465356, 5.58222404, 5.80643854,\n",
      "       5.924476  , 6.10441961, 7.22237492, 6.85005813, 7.02722826,\n",
      "       6.37471828, 6.52003279, 6.24482465, 6.54505968, 6.31225905,\n",
      "       6.21512918, 6.87486649, 6.88211703, 6.07669559, 6.54354181,\n",
      "       6.59821529, 6.30638275, 3.3029933 , 3.06827383, 3.09760928,\n",
      "       3.26887512, 3.72557907, 3.52089124, 2.89698534, 2.79436955,\n",
      "       3.16544833, 3.24328017, 3.27437096, 3.19569678, 3.14192338,\n",
      "       3.34744301, 3.15674777, 3.43183746, 4.55138268, 4.55032501,\n",
      "       4.31046638, 4.18279376, 4.28849268, 3.90975223, 4.57751064,\n",
      "       4.50310597, 4.17940946, 4.46245232, 4.96003075, 4.22252345,\n",
      "       3.63117042, 4.16580138, 4.58192163, 4.20606794, 5.23184075,\n",
      "       5.22772493, 5.72844534, 5.85556254, 5.76245923, 5.67063851,\n",
      "       5.21947689, 5.59815497, 5.55061626, 5.54088101, 5.49781389,\n",
      "       5.89540682, 5.48013444, 5.61401906, 5.66716437, 5.78270254,\n",
      "       6.50558333, 6.90110092, 6.90131845, 6.46770172, 6.39423699,\n",
      "       6.28765473, 6.83525863, 7.25414896, 6.3054183 , 5.6143157 ,\n",
      "       3.93037486, 2.81712074, 0.84911003, 0.86760035, 0.69134655,\n",
      "       0.62328954]),\n",
      " 'mean_test_score': array([0.87605   , 0.87713333, 0.87663333, 0.87645   , 0.8768    ,\n",
      "       0.87743333, 0.87746667, 0.87653333, 0.87733333, 0.87723333,\n",
      "       0.87838333, 0.87758333, 0.87848333, 0.87903333, 0.87868333,\n",
      "       0.87936667, 0.87891667, 0.87996667, 0.87958333, 0.8797    ,\n",
      "       0.87955   , 0.88008333, 0.88053333, 0.8802    , 0.88098333,\n",
      "       0.8797    , 0.88095   , 0.88056667, 0.88141667, 0.88168333,\n",
      "       0.88208333, 0.88168333, 0.88151667, 0.8817    , 0.88081667,\n",
      "       0.88155   , 0.88111667, 0.88176667, 0.8818    , 0.88115   ,\n",
      "       0.88263333, 0.88213333, 0.88233333, 0.8822    , 0.8833    ,\n",
      "       0.88331667, 0.88353333, 0.88303333, 0.88353333, 0.88303333,\n",
      "       0.88268333, 0.88298333, 0.8826    , 0.88308333, 0.88335   ,\n",
      "       0.8832    , 0.88391667, 0.88373333, 0.88425   , 0.8831    ,\n",
      "       0.88498333, 0.88468333, 0.88508333, 0.88458333, 0.87975   ,\n",
      "       0.87975   , 0.87936667, 0.88041667, 0.88      , 0.8805    ,\n",
      "       0.88066667, 0.88023333, 0.8804    , 0.88113333, 0.88118333,\n",
      "       0.88075   , 0.88123333, 0.88133333, 0.88171667, 0.88131667,\n",
      "       0.88256667, 0.88231667, 0.88176667, 0.88221667, 0.88251667,\n",
      "       0.88255   , 0.88276667, 0.88313333, 0.8828    , 0.88288333,\n",
      "       0.88313333, 0.8838    , 0.8834    , 0.8847    , 0.88406667,\n",
      "       0.88388333, 0.88365   , 0.88336667, 0.88316667, 0.88405   ,\n",
      "       0.88425   , 0.88405   , 0.88408333, 0.88425   , 0.88386667,\n",
      "       0.8839    , 0.88485   , 0.88451667, 0.88561667, 0.88455   ,\n",
      "       0.88548333, 0.88555   , 0.88481667, 0.88491667, 0.88473333,\n",
      "       0.88538333, 0.88521667, 0.88513333, 0.88596667, 0.88568333,\n",
      "       0.88508333, 0.88571667, 0.88665   , 0.88545   , 0.88608333,\n",
      "       0.88615   , 0.88673333, 0.886     , 0.8823    , 0.8817    ,\n",
      "       0.88175   , 0.88141667, 0.88175   , 0.88195   , 0.88196667,\n",
      "       0.882     , 0.88305   , 0.88253333, 0.88228333, 0.88198333,\n",
      "       0.8819    , 0.88266667, 0.8838    , 0.88296667, 0.88356667,\n",
      "       0.88355   , 0.8834    , 0.88346667, 0.88425   , 0.88451667,\n",
      "       0.88351667, 0.8843    , 0.88516667, 0.8849    , 0.88468333,\n",
      "       0.8831    , 0.88363333, 0.88468333, 0.88568333, 0.8852    ,\n",
      "       0.88501667, 0.88446667, 0.88495   , 0.88488333, 0.88558333,\n",
      "       0.88595   , 0.8854    , 0.8848    , 0.88606667, 0.8859    ,\n",
      "       0.88606667, 0.885     , 0.88518333, 0.88533333, 0.88628333,\n",
      "       0.88623333, 0.88678333, 0.88591667, 0.88515   , 0.8857    ,\n",
      "       0.88685   , 0.88598333, 0.88683333, 0.88591667, 0.88731667,\n",
      "       0.88721667, 0.8872    , 0.88633333, 0.88708333, 0.88716667,\n",
      "       0.88698333, 0.88733333, 0.88295   , 0.88321667, 0.88221667,\n",
      "       0.88368333, 0.88401667, 0.88378333, 0.8835    , 0.8824    ,\n",
      "       0.88386667, 0.88233333, 0.88341667, 0.88338333, 0.88496667,\n",
      "       0.88348333, 0.88411667, 0.88433333, 0.88541667, 0.88428333,\n",
      "       0.8849    , 0.88541667, 0.88646667, 0.88556667, 0.88586667,\n",
      "       0.8843    , 0.88596667, 0.8845    , 0.88603333, 0.88491667,\n",
      "       0.88705   , 0.88595   , 0.8862    , 0.88591667, 0.88623333,\n",
      "       0.88583333, 0.88576667, 0.88651667, 0.88748333, 0.88708333,\n",
      "       0.88666667, 0.88563333, 0.88661667, 0.8856    , 0.88621667,\n",
      "       0.88675   , 0.88793333, 0.88725   , 0.88726667, 0.887     ,\n",
      "       0.88761667, 0.88743333, 0.88671667, 0.88691667, 0.88765   ,\n",
      "       0.88795   , 0.8884    , 0.88661667, 0.88763333, 0.88695   ,\n",
      "       0.88696667, 0.8874    , 0.88881667, 0.88836667, 0.88851667,\n",
      "       0.88795   ]),\n",
      " 'param_learning_rate': masked_array(data=[0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
      "                   0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
      "                   0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
      "                   0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
      "                   0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
      "                   0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
      "                   0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
      "                   0.05, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07,\n",
      "                   0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07,\n",
      "                   0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07,\n",
      "                   0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07,\n",
      "                   0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07,\n",
      "                   0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07,\n",
      "                   0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07,\n",
      "                   0.07, 0.07, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
      "                   0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
      "                   0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
      "                   0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
      "                   0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
      "                   0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
      "                   0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
      "                   0.15, 0.15],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_max_iter': masked_array(data=[150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,\n",
      "                   150, 150, 150, 150, 150, 200, 200, 200, 200, 200, 200,\n",
      "                   200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 250,\n",
      "                   250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250,\n",
      "                   250, 250, 250, 250, 300, 300, 300, 300, 300, 300, 300,\n",
      "                   300, 300, 300, 300, 300, 300, 300, 300, 300, 150, 150,\n",
      "                   150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,\n",
      "                   150, 150, 150, 200, 200, 200, 200, 200, 200, 200, 200,\n",
      "                   200, 200, 200, 200, 200, 200, 200, 200, 250, 250, 250,\n",
      "                   250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250,\n",
      "                   250, 250, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "                   300, 300, 300, 300, 300, 300, 300, 150, 150, 150, 150,\n",
      "                   150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,\n",
      "                   150, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,\n",
      "                   200, 200, 200, 200, 200, 200, 250, 250, 250, 250, 250,\n",
      "                   250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250,\n",
      "                   300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "                   300, 300, 300, 300, 300, 150, 150, 150, 150, 150, 150,\n",
      "                   150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 200,\n",
      "                   200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,\n",
      "                   200, 200, 200, 200, 250, 250, 250, 250, 250, 250, 250,\n",
      "                   250, 250, 250, 250, 250, 250, 250, 250, 250, 300, 300,\n",
      "                   300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "                   300, 300, 300],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_max_leaf_nodes': masked_array(data=[35, 35, 35, 35, 37, 37, 37, 37, 39, 39, 39, 39, 41, 41,\n",
      "                   41, 41, 35, 35, 35, 35, 37, 37, 37, 37, 39, 39, 39, 39,\n",
      "                   41, 41, 41, 41, 35, 35, 35, 35, 37, 37, 37, 37, 39, 39,\n",
      "                   39, 39, 41, 41, 41, 41, 35, 35, 35, 35, 37, 37, 37, 37,\n",
      "                   39, 39, 39, 39, 41, 41, 41, 41, 35, 35, 35, 35, 37, 37,\n",
      "                   37, 37, 39, 39, 39, 39, 41, 41, 41, 41, 35, 35, 35, 35,\n",
      "                   37, 37, 37, 37, 39, 39, 39, 39, 41, 41, 41, 41, 35, 35,\n",
      "                   35, 35, 37, 37, 37, 37, 39, 39, 39, 39, 41, 41, 41, 41,\n",
      "                   35, 35, 35, 35, 37, 37, 37, 37, 39, 39, 39, 39, 41, 41,\n",
      "                   41, 41, 35, 35, 35, 35, 37, 37, 37, 37, 39, 39, 39, 39,\n",
      "                   41, 41, 41, 41, 35, 35, 35, 35, 37, 37, 37, 37, 39, 39,\n",
      "                   39, 39, 41, 41, 41, 41, 35, 35, 35, 35, 37, 37, 37, 37,\n",
      "                   39, 39, 39, 39, 41, 41, 41, 41, 35, 35, 35, 35, 37, 37,\n",
      "                   37, 37, 39, 39, 39, 39, 41, 41, 41, 41, 35, 35, 35, 35,\n",
      "                   37, 37, 37, 37, 39, 39, 39, 39, 41, 41, 41, 41, 35, 35,\n",
      "                   35, 35, 37, 37, 37, 37, 39, 39, 39, 39, 41, 41, 41, 41,\n",
      "                   35, 35, 35, 35, 37, 37, 37, 37, 39, 39, 39, 39, 41, 41,\n",
      "                   41, 41, 35, 35, 35, 35, 37, 37, 37, 37, 39, 39, 39, 39,\n",
      "                   41, 41, 41, 41],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_min_samples_leaf': masked_array(data=[22, 24, 26, 28, 22, 24, 26, 28, 22, 24, 26, 28, 22, 24,\n",
      "                   26, 28, 22, 24, 26, 28, 22, 24, 26, 28, 22, 24, 26, 28,\n",
      "                   22, 24, 26, 28, 22, 24, 26, 28, 22, 24, 26, 28, 22, 24,\n",
      "                   26, 28, 22, 24, 26, 28, 22, 24, 26, 28, 22, 24, 26, 28,\n",
      "                   22, 24, 26, 28, 22, 24, 26, 28, 22, 24, 26, 28, 22, 24,\n",
      "                   26, 28, 22, 24, 26, 28, 22, 24, 26, 28, 22, 24, 26, 28,\n",
      "                   22, 24, 26, 28, 22, 24, 26, 28, 22, 24, 26, 28, 22, 24,\n",
      "                   26, 28, 22, 24, 26, 28, 22, 24, 26, 28, 22, 24, 26, 28,\n",
      "                   22, 24, 26, 28, 22, 24, 26, 28, 22, 24, 26, 28, 22, 24,\n",
      "                   26, 28, 22, 24, 26, 28, 22, 24, 26, 28, 22, 24, 26, 28,\n",
      "                   22, 24, 26, 28, 22, 24, 26, 28, 22, 24, 26, 28, 22, 24,\n",
      "                   26, 28, 22, 24, 26, 28, 22, 24, 26, 28, 22, 24, 26, 28,\n",
      "                   22, 24, 26, 28, 22, 24, 26, 28, 22, 24, 26, 28, 22, 24,\n",
      "                   26, 28, 22, 24, 26, 28, 22, 24, 26, 28, 22, 24, 26, 28,\n",
      "                   22, 24, 26, 28, 22, 24, 26, 28, 22, 24, 26, 28, 22, 24,\n",
      "                   26, 28, 22, 24, 26, 28, 22, 24, 26, 28, 22, 24, 26, 28,\n",
      "                   22, 24, 26, 28, 22, 24, 26, 28, 22, 24, 26, 28, 22, 24,\n",
      "                   26, 28, 22, 24, 26, 28, 22, 24, 26, 28, 22, 24, 26, 28,\n",
      "                   22, 24, 26, 28],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'params': [{'learning_rate': 0.05,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.05,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.07,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.1,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 150,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 200,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 250,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 35,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 37,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.15,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 39,\n",
      "             'min_samples_leaf': 28},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 22},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 24},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 26},\n",
      "            {'learning_rate': 0.15,\n",
      "             'max_iter': 300,\n",
      "             'max_leaf_nodes': 41,\n",
      "             'min_samples_leaf': 28}],\n",
      " 'rank_test_score': array([256, 251, 253, 255, 252, 248, 247, 254, 249, 250, 245, 246, 244,\n",
      "       241, 243, 239, 242, 232, 237, 235, 238, 230, 224, 229, 218, 235,\n",
      "       219, 223, 209, 205, 191, 205, 208, 203, 220, 207, 217, 198, 197,\n",
      "       215, 175, 190, 182, 189, 155, 154, 143, 165, 142, 165, 173, 167,\n",
      "       176, 163, 153, 157, 128, 136, 119, 161,  92, 106,  88, 108, 234,\n",
      "       233, 239, 226, 231, 225, 222, 228, 227, 216, 214, 221, 213, 211,\n",
      "       202, 212, 177, 184, 199, 187, 180, 178, 172, 159, 171, 170, 159,\n",
      "       133, 149, 104, 124, 130, 138, 152, 158, 125, 119, 125, 123, 118,\n",
      "       131, 129, 100, 110,  70, 109,  75,  74, 101,  95, 103,  80,  82,\n",
      "        87,  54,  67,  88,  65,  36,  76,  48,  47,  33,  52, 185, 203,\n",
      "       200, 209, 200, 195, 194, 192, 164, 179, 186, 193, 196, 174, 133,\n",
      "       168, 140, 141, 149, 147, 119, 110, 144, 115,  85,  97, 105, 161,\n",
      "       139, 106,  67,  83,  90, 113,  94,  99,  72,  56,  79, 102,  49,\n",
      "        61,  49,  91,  84,  81,  42,  43,  31,  58,  86,  66,  29,  53,\n",
      "        30,  58,  15,  18,  19,  41,  21,  20,  25,  14, 169, 156, 187,\n",
      "       137, 127, 135, 145, 181, 132, 182, 148, 151,  93, 146, 122, 114,\n",
      "        78, 117,  97,  77,  40,  73,  62, 115,  55, 112,  51,  95,  23,\n",
      "        56,  46,  58,  43,  63,  64,  39,  11,  22,  35,  69,  37,  71,\n",
      "        45,  32,   7,  17,  16,  24,  10,  12,  34,  28,   8,   5,   3,\n",
      "        37,   9,  27,  26,  13,   1,   4,   2,   5], dtype=int32),\n",
      " 'split0_test_score': array([0.87358333, 0.87525   , 0.87308333, 0.87325   , 0.87558333,\n",
      "       0.87716667, 0.87616667, 0.87558333, 0.87583333, 0.87675   ,\n",
      "       0.878     , 0.875     , 0.87608333, 0.87725   , 0.879     ,\n",
      "       0.87733333, 0.87616667, 0.87725   , 0.876     , 0.87658333,\n",
      "       0.87858333, 0.87983333, 0.87916667, 0.87841667, 0.88008333,\n",
      "       0.87925   , 0.8815    , 0.879     , 0.88008333, 0.87975   ,\n",
      "       0.88158333, 0.8795    , 0.87833333, 0.87933333, 0.87633333,\n",
      "       0.87808333, 0.87916667, 0.88216667, 0.88125   , 0.87941667,\n",
      "       0.8815    , 0.88083333, 0.88175   , 0.881     , 0.88175   ,\n",
      "       0.88158333, 0.88216667, 0.88108333, 0.88058333, 0.88083333,\n",
      "       0.87991667, 0.88      , 0.88041667, 0.88291667, 0.88291667,\n",
      "       0.88208333, 0.88233333, 0.88225   , 0.88458333, 0.88316667,\n",
      "       0.88341667, 0.88308333, 0.88383333, 0.88258333, 0.87741667,\n",
      "       0.87833333, 0.87716667, 0.87758333, 0.88091667, 0.87866667,\n",
      "       0.87925   , 0.8775    , 0.87991667, 0.87958333, 0.88083333,\n",
      "       0.87833333, 0.88016667, 0.87941667, 0.87966667, 0.87975   ,\n",
      "       0.88041667, 0.88125   , 0.87941667, 0.88025   , 0.88258333,\n",
      "       0.88075   , 0.88175   , 0.88041667, 0.88166667, 0.88183333,\n",
      "       0.88233333, 0.8815    , 0.88133333, 0.88408333, 0.88125   ,\n",
      "       0.88258333, 0.88241667, 0.883     , 0.88091667, 0.8825    ,\n",
      "       0.88408333, 0.88225   , 0.883     , 0.88175   , 0.88366667,\n",
      "       0.883     , 0.8845    , 0.88308333, 0.88358333, 0.88383333,\n",
      "       0.88391667, 0.88466667, 0.88341667, 0.88483333, 0.88258333,\n",
      "       0.8835    , 0.88533333, 0.88408333, 0.885     , 0.88458333,\n",
      "       0.88458333, 0.88575   , 0.88525   , 0.88266667, 0.88458333,\n",
      "       0.88408333, 0.88516667, 0.88525   , 0.88041667, 0.8825    ,\n",
      "       0.87991667, 0.88008333, 0.881     , 0.88125   , 0.87916667,\n",
      "       0.88158333, 0.88208333, 0.883     , 0.88025   , 0.88208333,\n",
      "       0.88091667, 0.88191667, 0.88258333, 0.88141667, 0.88191667,\n",
      "       0.88608333, 0.88241667, 0.88241667, 0.88216667, 0.88408333,\n",
      "       0.88283333, 0.88366667, 0.88441667, 0.88291667, 0.88383333,\n",
      "       0.88458333, 0.88408333, 0.88483333, 0.8835    , 0.88341667,\n",
      "       0.88466667, 0.88675   , 0.88366667, 0.88441667, 0.88383333,\n",
      "       0.88583333, 0.88616667, 0.88316667, 0.886     , 0.88683333,\n",
      "       0.885     , 0.88608333, 0.88691667, 0.88458333, 0.88433333,\n",
      "       0.88466667, 0.886     , 0.88791667, 0.8845    , 0.88591667,\n",
      "       0.88533333, 0.88375   , 0.88608333, 0.88525   , 0.88883333,\n",
      "       0.88791667, 0.88741667, 0.88733333, 0.88841667, 0.88641667,\n",
      "       0.88633333, 0.88741667, 0.8795    , 0.88208333, 0.88233333,\n",
      "       0.883     , 0.88366667, 0.88325   , 0.88241667, 0.8825    ,\n",
      "       0.88216667, 0.88116667, 0.88183333, 0.88358333, 0.88575   ,\n",
      "       0.88441667, 0.8835    , 0.88508333, 0.88308333, 0.88216667,\n",
      "       0.88625   , 0.88608333, 0.88791667, 0.88558333, 0.8845    ,\n",
      "       0.88383333, 0.88575   , 0.88225   , 0.88475   , 0.88533333,\n",
      "       0.88766667, 0.88825   , 0.88616667, 0.88566667, 0.88616667,\n",
      "       0.88358333, 0.88616667, 0.88658333, 0.88808333, 0.88858333,\n",
      "       0.88608333, 0.88375   , 0.88483333, 0.88341667, 0.886     ,\n",
      "       0.88725   , 0.88683333, 0.88858333, 0.88783333, 0.887     ,\n",
      "       0.88741667, 0.88616667, 0.88666667, 0.88583333, 0.88783333,\n",
      "       0.88916667, 0.88966667, 0.884     , 0.88641667, 0.88491667,\n",
      "       0.88591667, 0.887     , 0.88908333, 0.88916667, 0.88966667,\n",
      "       0.888     ]),\n",
      " 'split1_test_score': array([0.88066667, 0.88066667, 0.88083333, 0.87925   , 0.88      ,\n",
      "       0.87983333, 0.88058333, 0.87825   , 0.88133333, 0.88075   ,\n",
      "       0.88166667, 0.881     , 0.88316667, 0.8815    , 0.8825    ,\n",
      "       0.88225   , 0.88175   , 0.884     , 0.88275   , 0.88325   ,\n",
      "       0.8815    , 0.88291667, 0.88308333, 0.8815    , 0.8855    ,\n",
      "       0.88158333, 0.88375   , 0.885     , 0.88483333, 0.88358333,\n",
      "       0.88575   , 0.88475   , 0.88425   , 0.88566667, 0.8845    ,\n",
      "       0.88375   , 0.88408333, 0.88358333, 0.8845    , 0.88175   ,\n",
      "       0.88725   , 0.88608333, 0.88475   , 0.88583333, 0.88633333,\n",
      "       0.88475   , 0.88575   , 0.88533333, 0.887     , 0.88666667,\n",
      "       0.88516667, 0.88475   , 0.88533333, 0.885     , 0.88591667,\n",
      "       0.88441667, 0.88708333, 0.8875    , 0.88708333, 0.88641667,\n",
      "       0.88875   , 0.88791667, 0.88808333, 0.88816667, 0.88133333,\n",
      "       0.88275   , 0.88175   , 0.88358333, 0.88041667, 0.88233333,\n",
      "       0.88291667, 0.88341667, 0.88266667, 0.88241667, 0.88308333,\n",
      "       0.88291667, 0.883     , 0.885     , 0.88308333, 0.88333333,\n",
      "       0.88341667, 0.88466667, 0.8845    , 0.88408333, 0.88383333,\n",
      "       0.88491667, 0.88491667, 0.88441667, 0.88433333, 0.88466667,\n",
      "       0.88483333, 0.88683333, 0.88491667, 0.88741667, 0.88583333,\n",
      "       0.88566667, 0.88558333, 0.88725   , 0.88541667, 0.88591667,\n",
      "       0.8865    , 0.88616667, 0.8865    , 0.88591667, 0.88608333,\n",
      "       0.886     , 0.88733333, 0.88675   , 0.88683333, 0.8865    ,\n",
      "       0.88666667, 0.88741667, 0.88733333, 0.88783333, 0.88725   ,\n",
      "       0.88825   , 0.88716667, 0.88716667, 0.88875   , 0.88666667,\n",
      "       0.8865    , 0.88841667, 0.88783333, 0.888     , 0.88775   ,\n",
      "       0.88975   , 0.88908333, 0.88875   , 0.886     , 0.88391667,\n",
      "       0.88466667, 0.88358333, 0.88541667, 0.88633333, 0.88466667,\n",
      "       0.88283333, 0.88641667, 0.88491667, 0.88633333, 0.88466667,\n",
      "       0.88366667, 0.88525   , 0.88725   , 0.88491667, 0.88783333,\n",
      "       0.88475   , 0.88666667, 0.88458333, 0.88958333, 0.88866667,\n",
      "       0.88525   , 0.88516667, 0.88866667, 0.88758333, 0.88883333,\n",
      "       0.88508333, 0.88433333, 0.88683333, 0.89016667, 0.88633333,\n",
      "       0.88766667, 0.88691667, 0.88783333, 0.8875    , 0.88933333,\n",
      "       0.88933333, 0.88591667, 0.88741667, 0.88941667, 0.88683333,\n",
      "       0.89008333, 0.88816667, 0.88666667, 0.88875   , 0.88975   ,\n",
      "       0.88866667, 0.89025   , 0.8875    , 0.88958333, 0.88775   ,\n",
      "       0.89158333, 0.88941667, 0.88675   , 0.88733333, 0.89008333,\n",
      "       0.88966667, 0.89075   , 0.89025   , 0.8895    , 0.88925   ,\n",
      "       0.89083333, 0.88983333, 0.88591667, 0.88341667, 0.88316667,\n",
      "       0.88525   , 0.88641667, 0.88866667, 0.88475   , 0.88508333,\n",
      "       0.88633333, 0.88575   , 0.88441667, 0.88533333, 0.88775   ,\n",
      "       0.88558333, 0.88783333, 0.88675   , 0.88791667, 0.88625   ,\n",
      "       0.8865    , 0.8875    , 0.88833333, 0.8905    , 0.88608333,\n",
      "       0.88791667, 0.88891667, 0.88716667, 0.88716667, 0.88691667,\n",
      "       0.88966667, 0.8875    , 0.88883333, 0.88775   , 0.88808333,\n",
      "       0.88766667, 0.88791667, 0.88866667, 0.88991667, 0.89108333,\n",
      "       0.88841667, 0.88933333, 0.88883333, 0.88875   , 0.885     ,\n",
      "       0.889     , 0.88983333, 0.8895    , 0.88875   , 0.88766667,\n",
      "       0.88908333, 0.88908333, 0.88866667, 0.89041667, 0.891     ,\n",
      "       0.89125   , 0.88883333, 0.89033333, 0.88958333, 0.89058333,\n",
      "       0.88666667, 0.8895    , 0.89141667, 0.88983333, 0.88975   ,\n",
      "       0.8895    ]),\n",
      " 'split2_test_score': array([0.87933333, 0.87991667, 0.879     , 0.87966667, 0.88108333,\n",
      "       0.88091667, 0.88108333, 0.87916667, 0.88125   , 0.88041667,\n",
      "       0.881     , 0.88141667, 0.8815    , 0.88408333, 0.88058333,\n",
      "       0.88083333, 0.88266667, 0.88333333, 0.88316667, 0.88283333,\n",
      "       0.88433333, 0.88391667, 0.88541667, 0.88416667, 0.88416667,\n",
      "       0.88291667, 0.88316667, 0.88341667, 0.88541667, 0.88608333,\n",
      "       0.88616667, 0.88341667, 0.88566667, 0.885     , 0.88558333,\n",
      "       0.88525   , 0.88575   , 0.88491667, 0.88591667, 0.88533333,\n",
      "       0.88558333, 0.885     , 0.88558333, 0.88541667, 0.88683333,\n",
      "       0.88758333, 0.88825   , 0.88558333, 0.88691667, 0.88666667,\n",
      "       0.88666667, 0.88633333, 0.88733333, 0.88641667, 0.88533333,\n",
      "       0.88716667, 0.88741667, 0.88675   , 0.8865    , 0.88533333,\n",
      "       0.88916667, 0.88933333, 0.88966667, 0.88675   , 0.88533333,\n",
      "       0.88475   , 0.88341667, 0.88508333, 0.88333333, 0.88575   ,\n",
      "       0.88475   , 0.88341667, 0.88491667, 0.886     , 0.88458333,\n",
      "       0.88391667, 0.88475   , 0.88575   , 0.88725   , 0.88358333,\n",
      "       0.88808333, 0.88608333, 0.88566667, 0.88683333, 0.88508333,\n",
      "       0.88725   , 0.88575   , 0.88741667, 0.88666667, 0.88741667,\n",
      "       0.88758333, 0.88833333, 0.88766667, 0.89058333, 0.88983333,\n",
      "       0.88808333, 0.88883333, 0.88725   , 0.88775   , 0.88875   ,\n",
      "       0.88733333, 0.89      , 0.886     , 0.88883333, 0.8875    ,\n",
      "       0.88958333, 0.88883333, 0.88783333, 0.89033333, 0.89025   ,\n",
      "       0.89075   , 0.88908333, 0.89025   , 0.88891667, 0.88666667,\n",
      "       0.88916667, 0.8885    , 0.89041667, 0.88816667, 0.88975   ,\n",
      "       0.88975   , 0.891     , 0.89141667, 0.88966667, 0.89133333,\n",
      "       0.8915    , 0.891     , 0.89      , 0.88475   , 0.88275   ,\n",
      "       0.88675   , 0.88333333, 0.884     , 0.88466667, 0.88641667,\n",
      "       0.88641667, 0.88783333, 0.88583333, 0.88316667, 0.88566667,\n",
      "       0.88733333, 0.88783333, 0.889     , 0.88916667, 0.88591667,\n",
      "       0.88658333, 0.88725   , 0.8865    , 0.8865    , 0.88616667,\n",
      "       0.88766667, 0.88808333, 0.88908333, 0.88866667, 0.88708333,\n",
      "       0.88683333, 0.88925   , 0.88966667, 0.89166667, 0.89058333,\n",
      "       0.8885    , 0.8875    , 0.88841667, 0.88725   , 0.888     ,\n",
      "       0.88816667, 0.88966667, 0.88791667, 0.89133333, 0.88816667,\n",
      "       0.88775   , 0.88741667, 0.88991667, 0.88958333, 0.89125   ,\n",
      "       0.8915    , 0.89016667, 0.8895    , 0.88783333, 0.88841667,\n",
      "       0.8905    , 0.88966667, 0.89358333, 0.89      , 0.89225   ,\n",
      "       0.88975   , 0.89041667, 0.88791667, 0.89091667, 0.89141667,\n",
      "       0.89083333, 0.89083333, 0.88766667, 0.88875   , 0.88658333,\n",
      "       0.88675   , 0.88933333, 0.88641667, 0.88908333, 0.88583333,\n",
      "       0.88833333, 0.885     , 0.88866667, 0.88491667, 0.88491667,\n",
      "       0.88675   , 0.8885    , 0.8875    , 0.88991667, 0.889     ,\n",
      "       0.88766667, 0.88841667, 0.891     , 0.8895    , 0.88991667,\n",
      "       0.8875    , 0.89091667, 0.88725   , 0.89183333, 0.88708333,\n",
      "       0.88783333, 0.88883333, 0.89083333, 0.8895    , 0.89016667,\n",
      "       0.89266667, 0.888     , 0.88966667, 0.892     , 0.89008333,\n",
      "       0.89075   , 0.88841667, 0.89066667, 0.88808333, 0.89166667,\n",
      "       0.888     , 0.89033333, 0.88891667, 0.8915    , 0.89158333,\n",
      "       0.89116667, 0.89283333, 0.88975   , 0.88983333, 0.89191667,\n",
      "       0.89116667, 0.89258333, 0.8905    , 0.89208333, 0.88958333,\n",
      "       0.89258333, 0.88866667, 0.89083333, 0.89108333, 0.89316667,\n",
      "       0.8925    ]),\n",
      " 'split3_test_score': array([0.87358333, 0.87358333, 0.87416667, 0.87483333, 0.87383333,\n",
      "       0.87483333, 0.87508333, 0.87383333, 0.87291667, 0.8735    ,\n",
      "       0.87533333, 0.87525   , 0.875     , 0.87591667, 0.87475   ,\n",
      "       0.8785    , 0.8765    , 0.877     , 0.87833333, 0.87733333,\n",
      "       0.87675   , 0.87766667, 0.87816667, 0.87791667, 0.87616667,\n",
      "       0.87658333, 0.87791667, 0.87791667, 0.87691667, 0.87925   ,\n",
      "       0.87833333, 0.87966667, 0.87858333, 0.87808333, 0.88016667,\n",
      "       0.88108333, 0.87758333, 0.87933333, 0.87791667, 0.87933333,\n",
      "       0.87766667, 0.87875   , 0.87916667, 0.8795    , 0.88033333,\n",
      "       0.88083333, 0.8805    , 0.88125   , 0.88091667, 0.87966667,\n",
      "       0.88233333, 0.88258333, 0.87983333, 0.87983333, 0.88108333,\n",
      "       0.88083333, 0.87891667, 0.8815    , 0.88216667, 0.88033333,\n",
      "       0.88041667, 0.8815    , 0.88108333, 0.88183333, 0.87741667,\n",
      "       0.87658333, 0.87633333, 0.8775    , 0.87741667, 0.87841667,\n",
      "       0.87783333, 0.87958333, 0.87558333, 0.878     , 0.879     ,\n",
      "       0.87925   , 0.87858333, 0.87633333, 0.87691667, 0.87841667,\n",
      "       0.8805    , 0.87941667, 0.87925   , 0.87933333, 0.88008333,\n",
      "       0.88058333, 0.88033333, 0.8825    , 0.87891667, 0.87833333,\n",
      "       0.881     , 0.8815    , 0.88208333, 0.87866667, 0.87933333,\n",
      "       0.88016667, 0.88008333, 0.88008333, 0.87991667, 0.88066667,\n",
      "       0.88191667, 0.88158333, 0.88125   , 0.88416667, 0.88025   ,\n",
      "       0.87966667, 0.88208333, 0.88275   , 0.8845    , 0.87908333,\n",
      "       0.88208333, 0.88108333, 0.88208333, 0.88191667, 0.88233333,\n",
      "       0.88133333, 0.88266667, 0.8835    , 0.88233333, 0.88491667,\n",
      "       0.88125   , 0.88166667, 0.884     , 0.88266667, 0.88466667,\n",
      "       0.88125   , 0.88325   , 0.882     , 0.87883333, 0.88016667,\n",
      "       0.877     , 0.87916667, 0.88116667, 0.87825   , 0.8785    ,\n",
      "       0.87933333, 0.88008333, 0.87941667, 0.881     , 0.87816667,\n",
      "       0.87783333, 0.87866667, 0.8815    , 0.88083333, 0.88      ,\n",
      "       0.88075   , 0.88008333, 0.88191667, 0.88283333, 0.88158333,\n",
      "       0.87866667, 0.88183333, 0.883     , 0.88283333, 0.88283333,\n",
      "       0.87858333, 0.87908333, 0.88066667, 0.88341667, 0.88408333,\n",
      "       0.88141667, 0.88      , 0.88216667, 0.883     , 0.88458333,\n",
      "       0.88258333, 0.88258333, 0.8815    , 0.88175   , 0.88408333,\n",
      "       0.88383333, 0.88033333, 0.88108333, 0.88158333, 0.88508333,\n",
      "       0.88358333, 0.88291667, 0.88233333, 0.8825    , 0.88241667,\n",
      "       0.88375   , 0.88266667, 0.88383333, 0.88375   , 0.88216667,\n",
      "       0.88441667, 0.88375   , 0.88208333, 0.8835    , 0.88333333,\n",
      "       0.88541667, 0.88541667, 0.88116667, 0.88108333, 0.88141667,\n",
      "       0.88133333, 0.87991667, 0.87983333, 0.88225   , 0.87858333,\n",
      "       0.87966667, 0.88016667, 0.879     , 0.88225   , 0.88283333,\n",
      "       0.881     , 0.8795    , 0.88175   , 0.88341667, 0.8825    ,\n",
      "       0.88375   , 0.88175   , 0.88183333, 0.88075   , 0.88408333,\n",
      "       0.88066667, 0.882     , 0.882     , 0.882     , 0.88425   ,\n",
      "       0.88441667, 0.88366667, 0.88275   , 0.884     , 0.88233333,\n",
      "       0.88241667, 0.88425   , 0.88241667, 0.88225   , 0.88283333,\n",
      "       0.88416667, 0.883     , 0.88308333, 0.88291667, 0.88266667,\n",
      "       0.88658333, 0.88475   , 0.88516667, 0.88475   , 0.88533333,\n",
      "       0.88575   , 0.88416667, 0.88616667, 0.88333333, 0.88266667,\n",
      "       0.88475   , 0.88516667, 0.88333333, 0.88441667, 0.88366667,\n",
      "       0.88458333, 0.88666667, 0.88591667, 0.88658333, 0.88533333,\n",
      "       0.88383333]),\n",
      " 'split4_test_score': array([0.87308333, 0.87625   , 0.87608333, 0.87525   , 0.8735    ,\n",
      "       0.87441667, 0.87441667, 0.87583333, 0.87533333, 0.87475   ,\n",
      "       0.87591667, 0.87525   , 0.87666667, 0.87641667, 0.87658333,\n",
      "       0.87791667, 0.8775    , 0.87825   , 0.87766667, 0.8785    ,\n",
      "       0.87658333, 0.87608333, 0.87683333, 0.879     , 0.879     ,\n",
      "       0.87816667, 0.87841667, 0.8775    , 0.87983333, 0.87975   ,\n",
      "       0.87858333, 0.88108333, 0.88075   , 0.88041667, 0.8775    ,\n",
      "       0.87958333, 0.879     , 0.87883333, 0.87941667, 0.87991667,\n",
      "       0.88116667, 0.88      , 0.88041667, 0.87925   , 0.88125   ,\n",
      "       0.88183333, 0.881     , 0.88191667, 0.88225   , 0.88133333,\n",
      "       0.87933333, 0.88125   , 0.88008333, 0.88125   , 0.8815    ,\n",
      "       0.8815    , 0.88383333, 0.88066667, 0.88091667, 0.88025   ,\n",
      "       0.88316667, 0.88158333, 0.88275   , 0.88358333, 0.87725   ,\n",
      "       0.87633333, 0.87816667, 0.87833333, 0.87791667, 0.87733333,\n",
      "       0.87858333, 0.87725   , 0.87891667, 0.87966667, 0.87841667,\n",
      "       0.87933333, 0.87966667, 0.88016667, 0.88166667, 0.8815    ,\n",
      "       0.88041667, 0.88016667, 0.88      , 0.88058333, 0.881     ,\n",
      "       0.87925   , 0.88108333, 0.88091667, 0.88241667, 0.88216667,\n",
      "       0.87991667, 0.88083333, 0.881     , 0.88275   , 0.88408333,\n",
      "       0.88291667, 0.88133333, 0.87925   , 0.88183333, 0.88241667,\n",
      "       0.88141667, 0.88025   , 0.88366667, 0.88058333, 0.88183333,\n",
      "       0.88125   , 0.8815    , 0.88216667, 0.88283333, 0.88308333,\n",
      "       0.884     , 0.8855    , 0.881     , 0.88108333, 0.88483333,\n",
      "       0.88466667, 0.88241667, 0.8805    , 0.88558333, 0.8825    ,\n",
      "       0.88333333, 0.88175   , 0.88475   , 0.88425   , 0.88208333,\n",
      "       0.88416667, 0.88516667, 0.884     , 0.8815    , 0.87916667,\n",
      "       0.88041667, 0.88091667, 0.87716667, 0.87925   , 0.88108333,\n",
      "       0.87983333, 0.87883333, 0.8795    , 0.88066667, 0.87933333,\n",
      "       0.87975   , 0.87966667, 0.87866667, 0.8785    , 0.88216667,\n",
      "       0.87958333, 0.88058333, 0.88191667, 0.88016667, 0.88208333,\n",
      "       0.88316667, 0.88275   , 0.88066667, 0.8825    , 0.88083333,\n",
      "       0.88041667, 0.88141667, 0.88141667, 0.87966667, 0.88158333,\n",
      "       0.88283333, 0.88116667, 0.88266667, 0.88225   , 0.88216667,\n",
      "       0.88383333, 0.88266667, 0.884     , 0.88183333, 0.88358333,\n",
      "       0.88366667, 0.883     , 0.88133333, 0.88216667, 0.881     ,\n",
      "       0.88275   , 0.88458333, 0.88233333, 0.88133333, 0.884     ,\n",
      "       0.88308333, 0.88441667, 0.88391667, 0.88325   , 0.88325   ,\n",
      "       0.88433333, 0.88366667, 0.88408333, 0.88308333, 0.88541667,\n",
      "       0.8815    , 0.88316667, 0.8805    , 0.88075   , 0.87758333,\n",
      "       0.88208333, 0.88075   , 0.88075   , 0.879     , 0.88      ,\n",
      "       0.88283333, 0.87958333, 0.88316667, 0.88083333, 0.88358333,\n",
      "       0.87966667, 0.88125   , 0.88058333, 0.88275   , 0.8815    ,\n",
      "       0.88033333, 0.88333333, 0.88325   , 0.8815    , 0.88475   ,\n",
      "       0.88158333, 0.88225   , 0.88383333, 0.88441667, 0.881     ,\n",
      "       0.88566667, 0.8815    , 0.88241667, 0.88266667, 0.88441667,\n",
      "       0.88283333, 0.8825    , 0.88525   , 0.88516667, 0.88283333,\n",
      "       0.88391667, 0.88366667, 0.88566667, 0.88483333, 0.88575   ,\n",
      "       0.88291667, 0.88791667, 0.88408333, 0.8835    , 0.88341667,\n",
      "       0.88466667, 0.88491667, 0.88233333, 0.88516667, 0.88483333,\n",
      "       0.88341667, 0.88575   , 0.88491667, 0.88566667, 0.886     ,\n",
      "       0.88508333, 0.88516667, 0.88683333, 0.88516667, 0.88466667,\n",
      "       0.88591667]),\n",
      " 'std_fit_time': array([ 7.04614776,  7.01734742, 10.77938926,  7.15361548,  9.86711078,\n",
      "       10.23604222,  8.65698477,  8.93901145,  1.1984201 ,  8.79257426,\n",
      "        8.25914228,  1.96391195,  9.84155701,  1.64353316,  1.78596124,\n",
      "        2.20634822,  1.70761933,  0.53960878,  7.27286446, 11.6972855 ,\n",
      "        4.08653869,  3.66009866,  3.631814  ,  5.95568633,  2.53141596,\n",
      "        3.22487096,  3.95585697, 10.5989387 ,  7.5424258 ,  6.52728348,\n",
      "        2.64443243,  4.21159787,  5.01007155,  2.15294548,  4.22617051,\n",
      "       14.43672608,  3.92172766, 10.96732172, 13.84957251,  2.55544081,\n",
      "       13.32845522, 15.26549207, 10.86677336, 14.53579967, 10.96002283,\n",
      "       10.62077002, 15.41867003, 15.94766979, 17.21738444,  9.1327996 ,\n",
      "        6.37842433, 10.06229493, 14.51289324,  9.40730653, 10.81008253,\n",
      "       14.58284679,  9.79165392,  5.41633107, 14.19751537, 16.05355108,\n",
      "        5.02271736, 13.28028272, 14.29757393, 10.51730468,  6.72665935,\n",
      "        4.97992657,  3.11605038, 10.48550064,  8.38302265,  5.43842964,\n",
      "       10.62432855,  6.99632968,  5.0289153 ,  7.12660701,  8.94510087,\n",
      "        2.2026862 ,  6.82394462, 12.01576735,  9.31868873,  9.69545084,\n",
      "        2.61542506, 11.06938385,  8.43963818, 12.62112237, 15.27970764,\n",
      "        8.48902814, 11.16786461, 12.91652925, 15.64458317, 10.45859289,\n",
      "        7.0384289 , 12.27945533,  3.62402461,  7.16435723,  2.42650297,\n",
      "        8.97236433, 14.24318528, 13.50642714, 10.614633  , 16.12212019,\n",
      "       12.1968246 ,  6.9563051 ,  6.54989232, 12.00958879, 13.69714164,\n",
      "       12.35755671, 14.498459  , 15.10151241, 15.56315109,  6.23807006,\n",
      "       15.103364  ,  8.00809949, 13.97242171,  7.23873309, 10.82961569,\n",
      "       10.0185855 , 15.78779445, 15.6585467 , 14.95858835,  8.71027929,\n",
      "        9.57187569, 12.56649586, 14.24567075, 16.72317975,  8.87713668,\n",
      "       18.46966091,  5.19353816, 12.98661647,  7.7527995 ,  3.9802059 ,\n",
      "        8.14697483,  8.40767134,  6.91740584,  3.85900844,  7.59214571,\n",
      "        2.5315114 ,  3.63353191,  7.12887387,  6.05884026,  7.44464983,\n",
      "        8.48381787,  8.8411213 ,  6.68479903, 11.17703333,  3.90600686,\n",
      "        9.18579037,  7.69938302,  7.67861876,  8.72931329,  4.25413693,\n",
      "       13.18402645,  9.00321324,  6.83912199, 10.75805516, 10.55682125,\n",
      "        5.80899107, 11.03082953,  4.66826349,  9.20657984, 12.1770602 ,\n",
      "       13.18371512,  4.22214011,  4.56174408, 16.12585795, 11.57930927,\n",
      "       10.49505285, 10.0624578 , 12.98035075, 13.98632488, 15.52107785,\n",
      "        4.13768873, 11.24932786, 14.8544799 ,  7.84206776, 13.91827053,\n",
      "       15.2200316 ,  7.32224281,  9.08363701,  8.6944243 , 12.36978653,\n",
      "       14.2215804 ,  7.37316799,  3.12524568, 14.62173111, 13.17916767,\n",
      "       11.62622894, 13.81178446, 19.02759408, 14.59758343,  5.13124494,\n",
      "       17.26789468, 15.72562064,  4.70205587,  5.6876578 ,  4.1702905 ,\n",
      "        7.07824646,  6.96524285,  6.75900089,  3.42342122,  1.76663386,\n",
      "        5.40134412, 11.26337984,  8.61787194, 10.93107115,  7.26553935,\n",
      "        3.55435906,  7.83287029,  9.38928704, 10.59803417,  8.54747854,\n",
      "       10.68772841, 11.2525235 ,  2.91473491,  5.73609526, 12.06204139,\n",
      "       13.69907526, 13.6206261 , 11.23009405,  7.30403897, 10.71268335,\n",
      "        3.76737172,  6.81498569, 10.63347319, 14.36967709, 10.00251928,\n",
      "        9.72501607, 12.8623296 , 10.75384165, 13.7617387 , 10.9967027 ,\n",
      "        7.27329657, 12.97660363,  9.13724056, 10.66030654, 12.8426439 ,\n",
      "        8.75785418, 15.29170189, 13.17280497, 13.17113294, 17.7047595 ,\n",
      "       11.81206566, 15.66886038, 13.40404734,  6.74699648, 14.54917708,\n",
      "       11.84362661, 10.77421352, 18.49810263, 16.48523281, 10.54397443,\n",
      "        5.46959293,  4.90882914,  3.62140671,  5.85070651,  7.32178796,\n",
      "        6.27574026]),\n",
      " 'std_score_time': array([0.29573031, 0.38211236, 0.42533345, 0.35361238, 0.31692211,\n",
      "       0.27670695, 0.28368904, 0.3161416 , 0.0476064 , 0.27227265,\n",
      "       0.41746562, 0.16996185, 0.28489787, 0.35250409, 0.13326808,\n",
      "       0.26812523, 0.08792423, 0.13029137, 0.44688359, 0.36494338,\n",
      "       0.35817842, 0.396008  , 0.43243452, 0.23577456, 0.18780049,\n",
      "       0.10544939, 0.14041454, 0.50095332, 0.3578987 , 0.13523874,\n",
      "       0.30880813, 0.52916388, 0.55251167, 0.50394655, 0.24299271,\n",
      "       0.41097006, 0.59913976, 0.98105476, 0.78079583, 0.14195992,\n",
      "       0.5468146 , 0.57689408, 0.35187498, 0.59246826, 0.54052674,\n",
      "       0.5015085 , 0.45272575, 0.68374432, 0.81926862, 0.57385859,\n",
      "       0.66618634, 0.16458055, 0.41643348, 0.34125826, 0.57379127,\n",
      "       0.38886632, 0.75995691, 0.46061693, 1.02867607, 0.71295369,\n",
      "       0.09334095, 0.24663609, 0.76407538, 0.3887443 , 0.61622813,\n",
      "       0.35966198, 0.36456872, 0.40673631, 0.51603534, 0.45158429,\n",
      "       0.64535804, 0.35617809, 0.32849525, 0.04600705, 0.36737512,\n",
      "       0.46244401, 0.37847097, 0.45089721, 0.34988586, 0.37631029,\n",
      "       0.26342658, 0.53248294, 0.40190699, 0.50271045, 0.49514388,\n",
      "       0.40311451, 0.47225745, 0.61068159, 0.57398238, 0.47522912,\n",
      "       0.61598412, 0.82885713, 0.1831483 , 0.48150719, 0.58993678,\n",
      "       0.5910508 , 1.06735601, 0.61817864, 0.60584114, 1.01542624,\n",
      "       0.6940195 , 0.68968921, 0.29315112, 0.8213093 , 0.49918888,\n",
      "       0.67647904, 0.44360827, 0.49969045, 0.87264396, 0.60844756,\n",
      "       0.47799507, 0.39991612, 0.54778088, 0.84245485, 0.31583509,\n",
      "       0.57835661, 0.47687172, 0.49681668, 0.88731742, 0.84180193,\n",
      "       0.33365828, 0.77849944, 0.37896556, 0.61438228, 0.76836899,\n",
      "       0.91972578, 0.29746992, 0.74087827, 0.47116179, 0.28337968,\n",
      "       0.42987319, 0.38475072, 0.33207483, 0.43637501, 0.37811971,\n",
      "       0.08249838, 0.36834311, 0.32451178, 0.32678656, 0.43426363,\n",
      "       0.4064207 , 0.44000763, 0.53282813, 0.32440366, 0.35413608,\n",
      "       0.43680995, 0.53415886, 0.63994833, 0.40002242, 0.33981635,\n",
      "       0.67266102, 0.77425466, 0.39547188, 0.1530654 , 0.66060779,\n",
      "       0.57388492, 0.70874174, 0.11353455, 0.75250389, 0.37409202,\n",
      "       0.68813238, 0.47745306, 0.54975122, 0.78805413, 0.52470971,\n",
      "       0.74871859, 0.26613471, 1.23469537, 0.71727595, 0.959511  ,\n",
      "       0.49905496, 0.69546202, 0.81059603, 0.64760053, 0.80569101,\n",
      "       0.64069929, 0.74949227, 1.17591255, 0.82375585, 0.95922555,\n",
      "       0.47970275, 0.77950929, 0.61223414, 0.55849268, 0.73139182,\n",
      "       1.16221046, 0.69465693, 0.63200121, 0.70787661, 0.63619285,\n",
      "       0.78999198, 0.93366805, 0.3539501 , 0.2606038 , 0.36558377,\n",
      "       0.34383402, 0.62677206, 0.4071987 , 0.33810329, 0.21757812,\n",
      "       0.39445651, 0.4791502 , 0.40190698, 0.44875794, 0.25397722,\n",
      "       0.28830956, 0.35349811, 0.41740048, 0.50772247, 0.87396494,\n",
      "       0.43512483, 1.07184788, 0.28287632, 0.58130961, 0.68412065,\n",
      "       0.37576549, 0.65508387, 0.36131024, 0.49709623, 0.32876996,\n",
      "       0.28415458, 0.51187633, 0.44196142, 0.43526565, 0.74788907,\n",
      "       0.60556673, 0.64432202, 0.77144739, 0.86764158, 0.6878027 ,\n",
      "       0.61617152, 0.82630141, 0.65944999, 0.59705169, 0.6687643 ,\n",
      "       0.56086604, 0.84497183, 0.5440619 , 0.59594438, 0.40750407,\n",
      "       1.09450806, 0.92081163, 1.25076665, 0.63635217, 0.5578471 ,\n",
      "       0.38889292, 0.58491198, 0.85810773, 0.53866836, 0.40169786,\n",
      "       1.50948135, 0.7529738 , 0.08184321, 0.11002468, 0.0136234 ,\n",
      "       0.01344247]),\n",
      " 'std_test_score': array([0.00325773, 0.00272621, 0.00290622, 0.00254875, 0.00315463,\n",
      "       0.00260096, 0.00280951, 0.00192686, 0.00337927, 0.00292708,\n",
      "       0.00257531, 0.00296414, 0.00323196, 0.00320399, 0.00276255,\n",
      "       0.0018683 , 0.00273861, 0.00305714, 0.00286162, 0.00279911,\n",
      "       0.00297518, 0.00298747, 0.00320962, 0.00233488, 0.00341988,\n",
      "       0.00228741, 0.00239479, 0.00305478, 0.00323136, 0.00269691,\n",
      "       0.00336691, 0.00207859, 0.00296713, 0.0030644 , 0.00368269,\n",
      "       0.00263186, 0.00319487, 0.00236256, 0.00300998, 0.00226654,\n",
      "       0.00340938, 0.00288126, 0.00246757, 0.00286289, 0.00272366,\n",
      "       0.00251518, 0.00298822, 0.00200111, 0.00285171, 0.00301552,\n",
      "       0.00286473, 0.00229819, 0.00311867, 0.00239734, 0.00196313,\n",
      "       0.00232176, 0.00315568, 0.0028242 , 0.00239386, 0.00252069,\n",
      "       0.00341459, 0.00329789, 0.00325619, 0.00245346, 0.00318809,\n",
      "       0.0033973 , 0.00274094, 0.00324594, 0.00215123, 0.00311938,\n",
      "       0.00268742, 0.00272254, 0.00319913, 0.0028179 , 0.00235431,\n",
      "       0.00222798, 0.00228485, 0.00354926, 0.00345631, 0.00200513,\n",
      "       0.00298905, 0.0026031 , 0.00274439, 0.00281593, 0.00181919,\n",
      "       0.00302288, 0.00215922, 0.00255691, 0.00260053, 0.0030348 ,\n",
      "       0.00276516, 0.00313475, 0.00254045, 0.00406393, 0.00365278,\n",
      "       0.00272977, 0.00316903, 0.00340653, 0.00294863, 0.00290144,\n",
      "       0.00236936, 0.00356783, 0.00194365, 0.00294911, 0.00265968,\n",
      "       0.00353451, 0.00286473, 0.00231024, 0.00271498, 0.00371057,\n",
      "       0.00301174, 0.00270935, 0.00345985, 0.0031051 , 0.00202306,\n",
      "       0.00293239, 0.00240578, 0.00338485, 0.00231816, 0.00242636,\n",
      "       0.00289108, 0.00366992, 0.00270976, 0.00287112, 0.00318111,\n",
      "       0.0038418 , 0.0028555 , 0.00297069, 0.00267945, 0.00175642,\n",
      "       0.00349881, 0.00175831, 0.00284312, 0.00310045, 0.00308968,\n",
      "       0.00253695, 0.0035137 , 0.00267218, 0.00226176, 0.0029109 ,\n",
      "       0.00330967, 0.00343309, 0.00379642, 0.0037188 , 0.00286812,\n",
      "       0.00285073, 0.00301312, 0.00180862, 0.00336237, 0.00263281,\n",
      "       0.00297788, 0.00218873, 0.00325875, 0.00265905, 0.00289655,\n",
      "       0.00308779, 0.00340163, 0.0033551 , 0.00451676, 0.00309103,\n",
      "       0.0027205 , 0.00320182, 0.00264344, 0.00215161, 0.00266979,\n",
      "       0.00253728, 0.00262541, 0.00248026, 0.00388637, 0.00176336,\n",
      "       0.00248406, 0.00292641, 0.00344214, 0.00329815, 0.00373742,\n",
      "       0.00332474, 0.00296208, 0.00300093, 0.00312623, 0.00224944,\n",
      "       0.00351639, 0.00295964, 0.0035676 , 0.00248719, 0.00393326,\n",
      "       0.00241097, 0.00307842, 0.00289732, 0.00319852, 0.00285385,\n",
      "       0.00353805, 0.00281218, 0.00322903, 0.00291814, 0.00290144,\n",
      "       0.00202031, 0.00351086, 0.00334274, 0.00333833, 0.00280446,\n",
      "       0.00308653, 0.00254569, 0.00318242, 0.00167216, 0.00172208,\n",
      "       0.00270873, 0.00354793, 0.00272641, 0.00293447, 0.00288174,\n",
      "       0.00261587, 0.00251275, 0.00340449, 0.00398866, 0.00213281,\n",
      "       0.0029705 , 0.00354401, 0.00229915, 0.00333025, 0.00222049,\n",
      "       0.00182696, 0.00286434, 0.00330513, 0.00246982, 0.00273526,\n",
      "       0.00389337, 0.00213268, 0.00256764, 0.00344779, 0.0035602 ,\n",
      "       0.00260342, 0.0026753 , 0.00275257, 0.00239351, 0.00296816,\n",
      "       0.00207833, 0.00203538, 0.00219026, 0.0028623 , 0.00272285,\n",
      "       0.00232295, 0.00317779, 0.00255038, 0.00275076, 0.00352783,\n",
      "       0.00327134, 0.00271181, 0.0031436 , 0.00280357, 0.00268152,\n",
      "       0.00289713, 0.00152971, 0.002156  , 0.00217217, 0.00314395,\n",
      "       0.00297284])}\n",
      "{'learning_rate': 0.15,\n",
      " 'max_iter': 300,\n",
      " 'max_leaf_nodes': 41,\n",
      " 'min_samples_leaf': 22}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'learning_rate': [0.05, 0.07, 0.1, 0.15], \n",
    "              'max_iter': [150, 200, 250, 300], \n",
    "              'max_leaf_nodes': [35, 37, 39, 41],\n",
    "              'min_samples_leaf': [22, 24, 26, 28]}\n",
    "modelHGBC = GridSearchCV(HistGradientBoostingClassifier(random_state=42), parameters, n_jobs = -1, verbose=10).fit(X, df.iloc[:,0])\n",
    "pprint(modelHGBC.cv_results_)\n",
    "pprint(modelHGBC.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
